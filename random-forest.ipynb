{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(523021, 73)"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn import metrics\n",
    "import  plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import os\n",
    "import colorlover  as cl\n",
    "from tqdm import tqdm\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import skew\n",
    "\n",
    "\n",
    "\n",
    "# environment settings\n",
    "data_path_out = 'Data/output/'\n",
    "\n",
    "#hack to avoid showing deprecationg warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "# Deserialize previously saved data from \"preprocessing\"\n",
    "with open(data_path_out+'train_pp.obj', 'rb') as train_pp:\n",
    "    train_df = pickle.load(train_pp)\n",
    "\n",
    "train_df_orig = train_df.copy()\n",
    "#Dummies\n",
    "train_df = pd.get_dummies(train_df)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that all closed stores don't have sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StoreID</th>\n",
       "      <th>Date</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>IsOpen</th>\n",
       "      <th>HasPromotions</th>\n",
       "      <th>NearestCompetitor</th>\n",
       "      <th>Region_AreaKM2</th>\n",
       "      <th>Region_GDP</th>\n",
       "      <th>Region_PopulationK</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>...</th>\n",
       "      <th>Events_Rain-Hail</th>\n",
       "      <th>Events_Rain-Hail-Thunderstorm</th>\n",
       "      <th>Events_Rain-Snow</th>\n",
       "      <th>Events_Rain-Snow-Hail</th>\n",
       "      <th>Events_Rain-Snow-Hail-Thunderstorm</th>\n",
       "      <th>Events_Rain-Snow-Thunderstorm</th>\n",
       "      <th>Events_Rain-Thunderstorm</th>\n",
       "      <th>Events_Snow</th>\n",
       "      <th>Events_Snow-Hail</th>\n",
       "      <th>Events_Thunderstorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [StoreID, Date, IsHoliday, IsOpen, HasPromotions, NearestCompetitor, Region_AreaKM2, Region_GDP, Region_PopulationK, CloudCover, Max_Dew_PointC, Max_Humidity, Max_Sea_Level_PressurehPa, Max_TemperatureC, Max_VisibilityKm, Max_Wind_SpeedKm_h, Mean_Dew_PointC, Mean_Humidity, Mean_Sea_Level_PressurehPa, Mean_TemperatureC, Mean_VisibilityKm, Mean_Wind_SpeedKm_h, Min_Dew_PointC, Min_Humidity, Min_Sea_Level_PressurehPa, Min_TemperatureC, Min_VisibilitykM, Precipitationmm, WindDirDegrees, Hol_and_open, Region_PD, NumberOfSales, NumberOfCustomers, StoreType_Hyper Market, StoreType_Standard Market, StoreType_Super Market, StoreType_Shopping Center, AssortmentType_General, AssortmentType_With Non-Food Department, AssortmentType_With Fish Department, Region_0, Region_1, Region_10, Region_2, Region_3, Region_4, Region_5, Region_7, Region_9, Region_6, Region_8, Events_Fog, Events_Fog-Rain, Events_Fog-Rain-Hail, Events_Fog-Rain-Hail-Thunderstorm, Events_Fog-Rain-Snow, Events_Fog-Rain-Snow-Hail, Events_Fog-Rain-Thunderstorm, Events_Fog-Snow, Events_Fog-Snow-Hail, Events_Fog-Thunderstorm, Events_Normal, Events_Rain, Events_Rain-Hail, Events_Rain-Hail-Thunderstorm, Events_Rain-Snow, Events_Rain-Snow-Hail, Events_Rain-Snow-Hail-Thunderstorm, Events_Rain-Snow-Thunderstorm, Events_Rain-Thunderstorm, Events_Snow, Events_Snow-Hail, Events_Thunderstorm]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 73 columns]"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[(train_df['IsOpen'] == False) & (train_df['NumberOfSales']>0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['day'] = train_df.Date.dt.day\n",
    "train_df['month'] = train_df.Date.dt.month\n",
    "train_df['year'] = train_df.Date.dt.year\n",
    "train_df['WeekOfYear'] = train_df.Date.dt.week\n",
    "train_df['DayOfWeek'] = train_df.Date.dt.dayofweek\n",
    "train_df['DaysInMonth'] = train_df.Date.dt.daysinmonth\n",
    "train_df['DayOfYear'] = train_df.Date.dt.dayofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New sales features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def num_of_features(regional_week_year,week,year,column_of_interest):\n",
    "    num_holidays=0\n",
    "\n",
    "    if week ==1:\n",
    "        week_before=[52,year-1]\n",
    "        week_after=[2,year]\n",
    "    if week == 52:\n",
    "        week_after=[1,year+1]\n",
    "        week_before=[51,year]\n",
    "    if (week>1) & (week<52):\n",
    "        week_before=[week-1,year]\n",
    "        week_after=[week+1,year]\n",
    "    \n",
    "    before_df = regional_week_year[(regional_week_year['WeekOfYear']==week_before[0])&\n",
    "                                  (regional_week_year['year']==week_before[1])]\n",
    "    \n",
    "    after_df = regional_week_year[(regional_week_year['WeekOfYear']==week_after[0])&\n",
    "                                  (regional_week_year['year']==week_after[1])]\n",
    "    this_df = regional_week_year[(regional_week_year['WeekOfYear']==week)&\n",
    "                                 (regional_week_year['year']==year)]\n",
    "    \n",
    "    num_ago = before_df[before_df[column_of_interest]][column_of_interest].sum()\n",
    "    num_next = after_df[after_df[column_of_interest]][column_of_interest].sum()\n",
    "    num_this = this_df[this_df[column_of_interest]][column_of_interest].sum()\n",
    "    \n",
    "    return num_ago,num_next,num_this\n",
    "\n",
    "def create_new_features(before,current,after,column_of_interest):\n",
    "    train_df[before] = 0\n",
    "    train_df[current]=0\n",
    "    train_df[after] = 0\n",
    "\n",
    "    region_list= [\"Region_\"+str(d) for d in range(0,11)]\n",
    "    for region in tqdm(region_list):\n",
    "        curr_region = train_df[train_df[region]==1]\n",
    "\n",
    "        #get all valid dates of that region\n",
    "        regional_week_year=curr_region[['WeekOfYear','year',column_of_interest]]\n",
    "\n",
    "        #get all store ids of that region\n",
    "        regional_stores=len(curr_region['StoreID'].unique())\n",
    "\n",
    "        week_year_list =regional_week_year[['WeekOfYear','year']].drop_duplicates().values.tolist()\n",
    "\n",
    "        for date in week_year_list:\n",
    "            num_ago,num_next,num_this = num_of_features(regional_week_year,\n",
    "                                                        date[0],\n",
    "                                                        date[1],\n",
    "                                                        column_of_interest)\n",
    "\n",
    "            train_df.at[((train_df['WeekOfYear']==date[0])&\n",
    "                         (train_df['year']==date[1])),before]=int(num_ago/regional_stores)\n",
    "            train_df.at[((train_df['WeekOfYear']==date[0])&\n",
    "                         (train_df['year']==date[1])),after]=int(num_next/regional_stores)\n",
    "            train_df.at[((train_df['WeekOfYear']==date[0])&\n",
    "                         (train_df['year']==date[1])),current]=int(num_this/regional_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [01:33<00:00,  8.49s/it]\n",
      "100%|██████████| 11/11 [01:41<00:00,  9.18s/it]\n"
     ]
    }
   ],
   "source": [
    "create_new_features('HolidaysWeekBefore','HolidaysWeekCurrent','HolidaysWeekAfter','IsHoliday')\n",
    "create_new_features('PromoWeekBefore','PromoWeekCurrent','PromoWeekAfter','HasPromotions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop NumberOfCustomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df =train_df.drop('NumberOfCustomers',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop closed stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_closed = (train_df['IsOpen']==False)\n",
    "# train_df=train_df[~mask_closed]\n",
    "# train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dates = pd.DatetimeIndex(train_df['Date'])\n",
    "month_dict = { d.strftime(\"%B%Y\") :datetime.strptime(d.strftime('%m-%Y'),'%m-%Y') for d in all_dates}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA -> useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08676394 0.14013837 0.18642801 0.22880135 0.26774312 0.30373827\n",
      " 0.33464839 0.36136781 0.38706481 0.41161405 0.4337767  0.45417583\n",
      " 0.47373189 0.49222562 0.50952897 0.52668562 0.54307328 0.55841678\n",
      " 0.57346096 0.58838674 0.60228555 0.61556069 0.62861582 0.64146395\n",
      " 0.65409994 0.66623234 0.67831901 0.69031365 0.70226763 0.71416616\n",
      " 0.72602676 0.73787622 0.74967435 0.76144226 0.77319758 0.7849209\n",
      " 0.79662476 0.80817145 0.81965038 0.83097105 0.84223815 0.85344159\n",
      " 0.86442826 0.87444916 0.88408404 0.89342405 0.90218681 0.91091824\n",
      " 0.91934789 0.92707515 0.93439986 0.94140194 0.94783679 0.9542359\n",
      " 0.9603776  0.96578768 0.97057429 0.97508781 0.97933529 0.98340357\n",
      " 0.98708497 0.9902571  0.99301703 0.99467599 0.9960731  0.99726338\n",
      " 0.99809355 0.99869529 0.99911185 0.99950283 0.99969718 0.99982258\n",
      " 0.99990028 0.99997304 0.99999987 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_df2 = train_df.drop('Date',axis=1)\n",
    "sc= StandardScaler()\n",
    "train_scaled = sc.fit_transform(train_df2.values)\n",
    "cov_mat = np.cov(train_scaled.T)\n",
    "eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n",
    "tot = sum(eigen_vals)\n",
    "var_exp = [(i/tot) for i in sorted(eigen_vals,reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print(cum_var_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Method Training and predicting one-hold out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def monthly_training(training_interval=['03-2017','02-2018'],\n",
    "                     verbose=False,\n",
    "                     regressor=RandomForestRegressor(n_estimators=50,n_jobs=-1)):\n",
    "    \n",
    "    init_date=datetime.strptime(training_interval[0],'%m-%Y')\n",
    "    end_date =datetime.strptime(training_interval[1],'%m-%Y')\n",
    "    \n",
    "    month_scores = []\n",
    "    y_test_list = []\n",
    "    predicted_list= []\n",
    "    predicted_df_list = []\n",
    "    training_months = []\n",
    "    training_df_list = []\n",
    "    for month_name, date in month_dict.items():\n",
    "\n",
    "        if (date >= init_date) & (date<= end_date) :\n",
    "                if verbose== True:\n",
    "                    print(\"Doing month\",month_name)\n",
    "                    \n",
    "                training_months.append(month_name)\n",
    "                mask = ((train_df['month']==date.month) & (train_df['year']==date.year))\n",
    "                test = train_df[mask]\n",
    "                train = train_df[~mask]\n",
    "                \n",
    "                y_train = train.NumberOfSales\n",
    "                X_train = train.drop('NumberOfSales',axis = 1)\n",
    "\n",
    "                y_test = test.NumberOfSales\n",
    "                X_test = test.drop('NumberOfSales',axis = 1)\n",
    "\n",
    "                X_train = X_train.drop('Date',axis=1)\n",
    "                X_test = X_test.drop('Date',axis=1)\n",
    "                \n",
    "                #slightly better with this scaler\n",
    "                scaler = RobustScaler()\n",
    "                X_train_scaled=scaler.fit(X_train).transform(X_train)\n",
    "                X_test_scaled=scaler.transform(X_test)\n",
    "                reg =  regressor.fit(X_train_scaled,y_train)\n",
    "                \n",
    "                train_copy  = train_df.drop(['NumberOfSales'], axis=1)\n",
    "                train_copy = train_copy.drop(['Date'],axis=1)\n",
    "                feat_labels = train_copy.columns[0:]\n",
    "                importances = reg.feature_importances_\n",
    "                indices = np.argsort(importances)[::-1]\n",
    "                for f in range(X_train_scaled.shape[1]):\n",
    "                    print(\"%2d %-*s %f\" %(f+1,30,feat_labels[indices[f]],importances[indices[f]]))\n",
    "                \n",
    "                current_score = reg.score(X_test_scaled,y_test)\n",
    "                current_prediction = reg.predict(X_test_scaled)\n",
    "                month_scores.append(current_score)\n",
    "                predicted_list.append(current_prediction)\n",
    "                y_test_list.append(y_test)\n",
    "                \n",
    "                if verbose == True:\n",
    "                    print(\"Month {} has shape {}\\n\\t\".format(month_name,test.shape))\n",
    "                    print(\"-Score {}\".format(current_score))\n",
    "                \n",
    "                \n",
    "                real_df = train_df.copy()\n",
    "                month_test_df = train_df[mask]\n",
    "                month_train_df= train_df[~mask]\n",
    "\n",
    "                month_test_df= month_test_df.drop('NumberOfSales',axis=1)\n",
    "                prediction_=pd.Series(current_prediction)\n",
    "                month_test_df['NumberOfSales']=prediction_.values.astype(int)\n",
    "                predicted_df = pd.concat([month_test_df,month_train_df]).reset_index()\n",
    "                predicted_df= predicted_df[list(train_df.columns.values)]\n",
    "                \n",
    "                predicted_df_list.append(predicted_df)\n",
    "                training_df_list.append(train)\n",
    "                \n",
    "    return {\n",
    "        'Scores' : month_scores,\n",
    "        'Real' : y_test_list,\n",
    "        'Predictions' : predicted_list,\n",
    "        'Training_dates': training_months,\n",
    "        'Training_df' : training_df_list,\n",
    "        'Predicted_df' : predicted_df_list\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor(n_estimators=50,n_jobs=-1)\n",
    "prediction_result = monthly_training(verbose=True,\n",
    "                                     training_interval=['05-2017','05-2017'],\n",
    "                                     regressor = reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2  Method : Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import defaultdict\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.linear_model import Lasso,Ridge,LinearRegression,RidgeCV,LassoCV\n",
    "\n",
    "results = {}\n",
    "sc= RobustScaler()\n",
    "for storeid in train_df.StoreID.unique():\n",
    "    train = train_df[train_df.StoreID == storeid]\n",
    "    y_train = train.NumberOfSales\n",
    "    X_train = train.drop('NumberOfSales',axis = 1)\n",
    "    X_train = X_train.drop('Date',axis=1)\n",
    "    X_train_scaled = sc.fit_transform(X_train)\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=50,max_depth=5,n_jobs=-1)\n",
    "    \n",
    "    kfold = KFold(n_splits=10,shuffle = True, random_state=7)\n",
    "    results[storeid] = cross_val_score(model, X_train_scaled, y_train, scoring='r2', cv=kfold)\n",
    "    print('Cross-validation for {} -> score: {:.4f} with +/- {:.4f}'\\\n",
    "          .format(storeid,results[storeid].mean(),results[storeid].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lanzi Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train by month\n",
    "def split_dataset_bymonth(test_year, test_months, train_set):\n",
    "    test_mask = (train.year == test_year) & train.month.isin(test_months)\n",
    "    \n",
    "    # define the train set\n",
    "    train_dataset = train[~test_mask]\n",
    "    x_train = train_dataset.drop('NumberOfSales', axis=1)\n",
    "    y_train = train_dataset.NumberOfSales\n",
    "    \n",
    "    # define the test set\n",
    "    test_dataset = train[test_mask]\n",
    "    x_test = test_dataset.drop('NumberOfSales', axis=1)\n",
    "    y_test = test_dataset.NumberOfSales\n",
    "    \n",
    "    return (x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "\n",
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop('Date',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store 1000 -> 0.9020\n",
      "store 1001 -> 0.7405\n",
      "store 1002 -> 0.9348\n",
      "store 1003 -> 0.9174\n",
      "store 1004 -> 0.9050\n",
      "store 1005 -> 0.9204\n",
      "store 1006 -> 0.8870\n",
      "store 1007 -> 0.9157\n",
      "store 1008 -> 0.5708\n",
      "store 1009 -> 0.9349\n",
      "store 1010 -> 0.8883\n",
      "store 1011 -> 0.8643\n",
      "store 1012 -> 0.9402\n",
      "store 1013 -> 0.9475\n",
      "store 1014 -> 0.8649\n",
      "store 1015 -> 0.9036\n",
      "store 1016 -> 0.8389\n",
      "store 1017 -> 0.9380\n",
      "store 1018 -> 0.9259\n",
      "store 1019 -> 0.9331\n",
      "store 1020 -> 0.8690\n",
      "store 1021 -> 0.9261\n",
      "store 1022 -> 0.9322\n",
      "store 1023 -> 0.9180\n",
      "store 1024 -> 0.9268\n",
      "store 1025 -> 0.8697\n",
      "store 1026 -> 0.9210\n",
      "store 1027 -> 0.9317\n",
      "store 1028 -> 0.8641\n",
      "store 1029 -> 0.8908\n",
      "store 1030 -> 0.8703\n",
      "store 1031 -> 0.8742\n",
      "store 1032 -> 0.9269\n",
      "store 1033 -> 0.9529\n",
      "store 1034 -> 0.8888\n",
      "store 1035 -> 0.9219\n",
      "store 1036 -> 0.9263\n",
      "store 1037 -> 0.6556\n",
      "store 1038 -> 0.9244\n",
      "store 1039 -> 0.9560\n",
      "store 1040 -> 0.9390\n",
      "store 1041 -> 0.8876\n",
      "store 1042 -> 0.8685\n",
      "store 1043 -> 0.8908\n",
      "store 1044 -> 0.9332\n",
      "store 1045 -> 0.9171\n",
      "store 1046 -> 0.9146\n",
      "store 1047 -> 0.8099\n",
      "store 1048 -> 0.8995\n",
      "store 1049 -> 0.6363\n",
      "store 1050 -> 0.9455\n",
      "store 1051 -> 0.8698\n",
      "store 1052 -> 0.9349\n",
      "store 1053 -> 0.8980\n",
      "store 1054 -> 0.7827\n",
      "store 1055 -> 0.9188\n",
      "store 1056 -> 0.8840\n",
      "store 1057 -> 0.9000\n",
      "store 1058 -> 0.8419\n",
      "store 1059 -> 0.9201\n",
      "store 1060 -> 0.9493\n",
      "store 1061 -> 0.9382\n",
      "store 1062 -> 0.8795\n",
      "store 1063 -> 0.9055\n",
      "store 1064 -> 0.9432\n",
      "store 1065 -> 0.9091\n",
      "store 1066 -> 0.9109\n",
      "store 1067 -> 0.9139\n",
      "store 1068 -> 0.9307\n",
      "store 1069 -> 0.9203\n",
      "store 1070 -> 0.9043\n",
      "store 1071 -> 0.9464\n",
      "store 1072 -> 0.9402\n",
      "store 1073 -> 0.8796\n",
      "store 1074 -> 0.6350\n",
      "store 1075 -> 0.8999\n",
      "store 1076 -> 0.9208\n",
      "store 1077 -> 0.4166\n",
      "store 1078 -> 0.6078\n",
      "store 1079 -> 0.8591\n",
      "store 1080 -> 0.7943\n",
      "store 1081 -> 0.9463\n",
      "store 1082 -> 0.8933\n",
      "store 1083 -> 0.9062\n",
      "store 1084 -> 0.9326\n",
      "store 1085 -> 0.9232\n",
      "store 1086 -> 0.8865\n",
      "store 1087 -> 0.8455\n",
      "store 1088 -> 0.9429\n",
      "store 1089 -> 0.9278\n",
      "store 1090 -> 0.8298\n",
      "store 1091 -> 0.9535\n",
      "store 1092 -> 0.8907\n",
      "store 1093 -> 0.8841\n",
      "store 1094 -> 0.9023\n",
      "store 1095 -> 0.9264\n",
      "store 1096 -> 0.8891\n",
      "store 1097 -> 0.8860\n",
      "store 1098 -> 0.8654\n",
      "store 1099 -> 0.8518\n",
      "store 1100 -> 0.9003\n",
      "store 1101 -> 0.8986\n",
      "store 1102 -> 0.9302\n",
      "store 1103 -> 0.8922\n",
      "store 1104 -> 0.8817\n",
      "store 1105 -> 0.7889\n",
      "store 1106 -> 0.8745\n",
      "store 1107 -> 0.9301\n",
      "store 1108 -> 0.9034\n",
      "store 1109 -> 0.8703\n",
      "store 1110 -> 0.9447\n",
      "store 1111 -> 0.8214\n",
      "store 1112 -> 0.9350\n",
      "store 1113 -> 0.9260\n",
      "store 1114 -> 0.9482\n",
      "store 1115 -> 0.9150\n",
      "store 1116 -> 0.9123\n",
      "store 1117 -> 0.9051\n",
      "store 1118 -> 0.9161\n",
      "store 1119 -> 0.9012\n",
      "store 1120 -> 0.8806\n",
      "store 1121 -> 0.9183\n",
      "store 1122 -> 0.9218\n",
      "store 1123 -> 0.8838\n",
      "store 1124 -> 0.8742\n",
      "store 1125 -> 0.9000\n",
      "store 1126 -> 0.9323\n",
      "store 1127 -> 0.9223\n",
      "store 1128 -> 0.8600\n",
      "store 1129 -> 0.8278\n",
      "store 1130 -> 0.8898\n",
      "store 1131 -> 0.3653\n",
      "store 1132 -> 0.8892\n",
      "store 1133 -> 0.9095\n",
      "store 1134 -> 0.9128\n",
      "store 1135 -> 0.9230\n",
      "store 1136 -> 0.9267\n",
      "store 1137 -> 0.8505\n",
      "store 1138 -> 0.8402\n",
      "store 1139 -> 0.9039\n",
      "store 1140 -> 0.9544\n",
      "store 1141 -> 0.8632\n",
      "store 1142 -> 0.8820\n",
      "store 1143 -> 0.8589\n",
      "store 1144 -> 0.9226\n",
      "store 1145 -> 0.9031\n",
      "store 1146 -> 0.8707\n",
      "store 1147 -> 0.9160\n",
      "store 1148 -> 0.8801\n",
      "store 1149 -> 0.9259\n",
      "store 1150 -> 0.9333\n",
      "store 1151 -> 0.9119\n",
      "store 1152 -> 0.9186\n",
      "store 1153 -> 0.9364\n",
      "store 1154 -> 0.8891\n",
      "store 1155 -> 0.9423\n",
      "store 1156 -> 0.9575\n",
      "store 1157 -> 0.9164\n",
      "store 1158 -> 0.9185\n",
      "store 1159 -> 0.8735\n",
      "store 1160 -> 0.9265\n",
      "store 1161 -> 0.8767\n",
      "store 1162 -> 0.9500\n",
      "store 1163 -> 0.9369\n",
      "store 1164 -> 0.9315\n",
      "store 1165 -> 0.8155\n",
      "store 1166 -> 0.8703\n",
      "store 1167 -> 0.8282\n",
      "store 1168 -> 0.8990\n",
      "store 1169 -> 0.8856\n",
      "store 1170 -> 0.9280\n",
      "store 1171 -> 0.7982\n",
      "store 1172 -> 0.9200\n",
      "store 1173 -> 0.7800\n",
      "store 1174 -> 0.9235\n",
      "store 1175 -> 0.9014\n",
      "store 1176 -> 0.9392\n",
      "store 1177 -> 0.9299\n",
      "store 1178 -> 0.9013\n",
      "store 1179 -> 0.9339\n",
      "store 1180 -> 0.9439\n",
      "store 1181 -> 0.9571\n",
      "store 1182 -> 0.8489\n",
      "store 1183 -> 0.8755\n",
      "store 1184 -> 0.9201\n",
      "store 1185 -> 0.9440\n",
      "store 1186 -> 0.8625\n",
      "store 1187 -> 0.8970\n",
      "store 1188 -> 0.9190\n",
      "store 1189 -> 0.9141\n",
      "store 1190 -> 0.8896\n",
      "store 1191 -> 0.9485\n",
      "store 1192 -> 0.8546\n",
      "store 1193 -> 0.9081\n",
      "store 1194 -> 0.8073\n",
      "store 1195 -> 0.9347\n",
      "store 1196 -> 0.9145\n",
      "store 1197 -> 0.9507\n",
      "store 1198 -> 0.9220\n",
      "store 1199 -> 0.8059\n",
      "store 1200 -> 0.8715\n",
      "store 1201 -> 0.9343\n",
      "store 1202 -> 0.8939\n",
      "store 1203 -> 0.3426\n",
      "store 1204 -> 0.8812\n",
      "store 1205 -> 0.8840\n",
      "store 1206 -> 0.8915\n",
      "store 1207 -> 0.9386\n",
      "store 1208 -> 0.9163\n",
      "store 1209 -> 0.9368\n",
      "store 1210 -> 0.9203\n",
      "store 1211 -> 0.8361\n",
      "store 1212 -> 0.9201\n",
      "store 1213 -> 0.8978\n",
      "store 1214 -> 0.6717\n",
      "store 1215 -> 0.9514\n",
      "store 1216 -> 0.9021\n",
      "store 1217 -> 0.9155\n",
      "store 1218 -> 0.9394\n",
      "store 1219 -> 0.8882\n",
      "store 1220 -> 0.9065\n",
      "store 1221 -> 0.9131\n",
      "store 1222 -> 0.9294\n",
      "store 1223 -> 0.8771\n",
      "store 1224 -> 0.9215\n",
      "store 1225 -> 0.9280\n",
      "store 1226 -> 0.9570\n",
      "store 1227 -> 0.8735\n",
      "store 1228 -> 0.9104\n",
      "store 1229 -> 0.5716\n",
      "store 1230 -> 0.8775\n",
      "store 1231 -> 0.8932\n",
      "store 1232 -> 0.8998\n",
      "store 1233 -> 0.9186\n",
      "store 1234 -> 0.9567\n",
      "store 1235 -> 0.9325\n",
      "store 1236 -> 0.8423\n",
      "store 1237 -> 0.8940\n",
      "store 1238 -> 0.9364\n",
      "store 1239 -> 0.9044\n",
      "store 1240 -> 0.9344\n",
      "store 1241 -> 0.9395\n",
      "store 1242 -> 0.8634\n",
      "store 1243 -> 0.9184\n",
      "store 1244 -> 0.8932\n",
      "store 1245 -> 0.9560\n",
      "store 1246 -> 0.8814\n",
      "store 1247 -> 0.9232\n",
      "store 1248 -> 0.6265\n",
      "store 1249 -> 0.9249\n",
      "store 1250 -> 0.9197\n",
      "store 1251 -> 0.9388\n",
      "store 1252 -> 0.9370\n",
      "store 1253 -> 0.9418\n",
      "store 1254 -> 0.8957\n",
      "store 1255 -> 0.9326\n",
      "store 1256 -> 0.7809\n",
      "store 1257 -> 0.8790\n",
      "store 1258 -> 0.9143\n",
      "store 1259 -> 0.8775\n",
      "store 1260 -> 0.8885\n",
      "store 1261 -> 0.9281\n",
      "store 1262 -> 0.9319\n",
      "store 1263 -> 0.9445\n",
      "store 1264 -> 0.8850\n",
      "store 1265 -> 0.8944\n",
      "store 1266 -> 0.9368\n",
      "store 1267 -> 0.7187\n",
      "store 1268 -> 0.8765\n",
      "store 1269 -> 0.8978\n",
      "store 1270 -> 0.9117\n",
      "store 1271 -> 0.8746\n",
      "store 1272 -> 0.9600\n",
      "store 1273 -> 0.8300\n",
      "store 1274 -> 0.9268\n",
      "store 1275 -> 0.9282\n",
      "store 1276 -> 0.9457\n",
      "store 1277 -> 0.8695\n",
      "store 1278 -> 0.9313\n",
      "store 1279 -> 0.8522\n",
      "store 1280 -> 0.1281\n",
      "store 1281 -> 0.8267\n",
      "store 1282 -> 0.9211\n",
      "store 1283 -> 0.9433\n",
      "store 1284 -> 0.8878\n",
      "store 1285 -> 0.9251\n",
      "store 1286 -> 0.9504\n",
      "store 1287 -> 0.9440\n",
      "store 1288 -> 0.9424\n",
      "store 1289 -> 0.9149\n",
      "store 1290 -> 0.9279\n",
      "store 1291 -> 0.8515\n",
      "store 1292 -> 0.9401\n",
      "store 1293 -> 0.8949\n",
      "store 1294 -> 0.9061\n",
      "store 1295 -> 0.9176\n",
      "store 1296 -> 0.9207\n",
      "store 1297 -> 0.9392\n",
      "store 1298 -> 0.9098\n",
      "store 1299 -> 0.9078\n",
      "store 1300 -> 0.9430\n",
      "store 1301 -> 0.8845\n",
      "store 1302 -> 0.9181\n",
      "store 1303 -> 0.8283\n",
      "store 1304 -> 0.9392\n",
      "store 1305 -> 0.8739\n",
      "store 1306 -> 0.8739\n",
      "store 1307 -> 0.5156\n",
      "store 1308 -> 0.9416\n",
      "store 1309 -> 0.9243\n",
      "store 1310 -> 0.9280\n",
      "store 1311 -> 0.9115\n",
      "store 1312 -> 0.7944\n",
      "store 1313 -> 0.9332\n",
      "store 1314 -> 0.9334\n",
      "store 1315 -> 0.8415\n",
      "store 1316 -> 0.9387\n",
      "store 1317 -> 0.9224\n",
      "store 1318 -> 0.9240\n",
      "store 1319 -> 0.8769\n",
      "store 1320 -> 0.9184\n",
      "store 1321 -> 0.9241\n",
      "store 1322 -> 0.8570\n",
      "store 1323 -> 0.8961\n",
      "store 1324 -> 0.9002\n",
      "store 1325 -> 0.9231\n",
      "store 1326 -> 0.8096\n",
      "store 1327 -> 0.9371\n",
      "store 1328 -> 0.9326\n",
      "store 1329 -> 0.9327\n",
      "store 1330 -> 0.2698\n",
      "store 1331 -> 0.8766\n",
      "store 1332 -> 0.8811\n",
      "store 1333 -> 0.9275\n",
      "store 1334 -> 0.9399\n",
      "store 1335 -> 0.9171\n",
      "store 1336 -> 0.7398\n",
      "store 1337 -> 0.8756\n",
      "store 1338 -> 0.9033\n",
      "store 1339 -> 0.7413\n",
      "store 1340 -> 0.9245\n",
      "store 1341 -> 0.9138\n",
      "store 1342 -> 0.9529\n",
      "store 1343 -> 0.9254\n",
      "store 1344 -> 0.9055\n",
      "store 1345 -> 0.3573\n",
      "store 1346 -> -0.3041\n",
      "store 1347 -> 0.9377\n",
      "store 1348 -> 0.8904\n",
      "store 1349 -> 0.6983\n",
      "store 1350 -> 0.9253\n",
      "store 1351 -> 0.8326\n",
      "store 1352 -> 0.8300\n",
      "store 1353 -> 0.8783\n",
      "store 1354 -> 0.9566\n",
      "store 1355 -> 0.9007\n",
      "store 1356 -> 0.9046\n",
      "store 1357 -> 0.7827\n",
      "store 1358 -> 0.9476\n",
      "store 1359 -> 0.9055\n",
      "store 1360 -> 0.8273\n",
      "store 1361 -> 0.9517\n",
      "store 1362 -> 0.9058\n",
      "store 1363 -> 0.9360\n",
      "store 1364 -> 0.9069\n",
      "store 1365 -> 0.9152\n",
      "store 1366 -> 0.9238\n",
      "store 1367 -> 0.8590\n",
      "store 1368 -> 0.8490\n",
      "store 1369 -> 0.8920\n",
      "store 1370 -> 0.7803\n",
      "store 1371 -> 0.5832\n",
      "store 1372 -> 0.8816\n",
      "store 1373 -> 0.9392\n",
      "store 1374 -> 0.9042\n",
      "store 1375 -> 0.9247\n",
      "store 1376 -> 0.9344\n",
      "store 1377 -> 0.9436\n",
      "store 1378 -> 0.9259\n",
      "store 1379 -> 0.8606\n",
      "store 1380 -> 0.9070\n",
      "store 1381 -> 0.9254\n",
      "store 1382 -> 0.9100\n",
      "store 1383 -> 0.9324\n",
      "store 1384 -> 0.9393\n",
      "store 1385 -> 0.8670\n",
      "store 1386 -> 0.9573\n",
      "store 1387 -> 0.4104\n",
      "store 1388 -> 0.9091\n",
      "store 1389 -> 0.9006\n",
      "store 1390 -> 0.8887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store 1391 -> 0.8759\n",
      "store 1392 -> 0.9339\n",
      "store 1393 -> 0.9529\n",
      "store 1394 -> 0.9211\n",
      "store 1395 -> 0.9156\n",
      "store 1396 -> 0.9346\n",
      "store 1397 -> 0.9141\n",
      "store 1398 -> 0.9208\n",
      "store 1399 -> 0.8961\n",
      "store 1400 -> 0.9204\n",
      "store 1401 -> 0.8609\n",
      "store 1402 -> 0.9593\n",
      "store 1403 -> 0.8918\n",
      "store 1404 -> 0.9232\n",
      "store 1405 -> 0.9271\n",
      "store 1406 -> 0.8110\n",
      "store 1407 -> 0.6429\n",
      "store 1408 -> 0.8897\n",
      "store 1409 -> 0.8642\n",
      "store 1410 -> 0.8024\n",
      "store 1411 -> 0.8769\n",
      "store 1412 -> 0.9696\n",
      "store 1413 -> 0.8571\n",
      "store 1414 -> 0.9040\n",
      "store 1415 -> 0.9190\n",
      "store 1416 -> 0.8973\n",
      "store 1417 -> 0.8811\n",
      "store 1418 -> 0.9310\n",
      "store 1419 -> 0.9063\n",
      "store 1420 -> 0.9409\n",
      "store 1421 -> 0.8955\n",
      "store 1422 -> 0.4528\n",
      "store 1423 -> 0.9509\n",
      "store 1424 -> 0.8907\n",
      "store 1425 -> 0.9656\n",
      "store 1426 -> 0.9144\n",
      "store 1427 -> 0.9118\n",
      "store 1428 -> 0.9243\n",
      "store 1429 -> 0.8121\n",
      "store 1430 -> 0.8628\n",
      "store 1431 -> 0.9251\n",
      "store 1432 -> 0.8663\n",
      "store 1433 -> 0.8643\n",
      "store 1434 -> 0.9354\n",
      "store 1435 -> 0.9167\n",
      "store 1436 -> 0.8752\n",
      "store 1437 -> 0.9393\n",
      "store 1438 -> 0.8797\n",
      "store 1439 -> 0.8955\n",
      "store 1440 -> 0.9458\n",
      "store 1441 -> 0.9269\n",
      "store 1442 -> 0.9086\n",
      "store 1443 -> 0.8482\n",
      "store 1444 -> 0.8991\n",
      "store 1445 -> 0.8992\n",
      "store 1446 -> 0.8978\n",
      "store 1447 -> 0.9485\n",
      "store 1448 -> 0.9256\n",
      "store 1449 -> 0.9267\n",
      "store 1450 -> 0.8568\n",
      "store 1451 -> 0.8161\n",
      "store 1452 -> 0.9341\n",
      "store 1453 -> 0.9371\n",
      "store 1454 -> 0.9518\n",
      "store 1455 -> 0.9304\n",
      "store 1456 -> 0.9193\n",
      "store 1457 -> 0.9227\n",
      "store 1458 -> 0.9121\n",
      "store 1459 -> 0.9370\n",
      "store 1460 -> 0.8688\n",
      "store 1461 -> 0.9185\n",
      "store 1462 -> 0.9169\n",
      "store 1463 -> 0.6012\n",
      "store 1464 -> 0.7690\n",
      "store 1465 -> 0.9184\n",
      "store 1466 -> 0.8947\n",
      "store 1467 -> 0.9343\n",
      "store 1468 -> 0.9395\n",
      "store 1469 -> 0.9081\n",
      "store 1470 -> 0.9001\n",
      "store 1471 -> 0.9033\n",
      "store 1472 -> 0.9246\n",
      "store 1473 -> 0.9103\n",
      "store 1474 -> 0.9343\n",
      "store 1475 -> 0.9355\n",
      "store 1476 -> 0.9080\n",
      "store 1477 -> 0.6356\n",
      "store 1478 -> 0.9103\n",
      "store 1479 -> 0.9191\n",
      "store 1480 -> 0.8697\n",
      "store 1481 -> 0.8963\n",
      "store 1482 -> 0.8959\n",
      "store 1483 -> 0.9230\n",
      "store 1484 -> 0.9300\n",
      "store 1485 -> 0.8925\n",
      "store 1486 -> 0.9354\n",
      "store 1487 -> 0.9236\n",
      "store 1488 -> 0.9365\n",
      "store 1489 -> 0.9131\n",
      "store 1490 -> 0.9229\n",
      "store 1491 -> 0.9399\n",
      "store 1492 -> 0.9247\n",
      "store 1493 -> 0.8539\n",
      "store 1494 -> 0.9033\n",
      "store 1495 -> 0.6476\n",
      "store 1496 -> 0.8944\n",
      "store 1497 -> 0.8285\n",
      "store 1498 -> 0.9243\n",
      "store 1499 -> 0.9056\n",
      "store 1500 -> 0.8944\n",
      "store 1501 -> 0.9435\n",
      "store 1502 -> 0.8433\n",
      "store 1503 -> 0.9093\n",
      "store 1504 -> 0.9341\n",
      "store 1505 -> 0.9034\n",
      "store 1506 -> 0.9245\n",
      "store 1507 -> 0.9239\n",
      "store 1508 -> 0.9086\n",
      "store 1509 -> 0.9051\n",
      "store 1510 -> 0.8802\n",
      "store 1511 -> 0.9292\n",
      "store 1512 -> 0.8118\n",
      "store 1513 -> 0.8152\n",
      "store 1514 -> 0.9374\n",
      "store 1515 -> 0.8906\n",
      "store 1516 -> 0.9164\n",
      "store 1517 -> 0.8401\n",
      "store 1518 -> 0.9447\n",
      "store 1519 -> 0.8889\n",
      "store 1520 -> 0.8226\n",
      "store 1521 -> 0.9338\n",
      "store 1522 -> 0.8619\n",
      "store 1523 -> 0.8998\n",
      "store 1524 -> 0.9193\n",
      "store 1525 -> 0.9155\n",
      "store 1526 -> 0.8610\n",
      "store 1527 -> 0.7880\n",
      "store 1528 -> 0.9059\n",
      "store 1529 -> 0.8420\n",
      "store 1530 -> 0.8815\n",
      "store 1531 -> 0.9356\n",
      "store 1532 -> 0.8896\n",
      "store 1533 -> 0.9089\n",
      "store 1534 -> 0.9306\n",
      "store 1535 -> 0.9305\n",
      "store 1536 -> 0.9009\n",
      "store 1537 -> 0.8700\n",
      "store 1538 -> 0.9564\n",
      "store 1539 -> 0.8215\n",
      "store 1540 -> 0.8011\n",
      "store 1541 -> 0.8998\n",
      "store 1542 -> 0.9155\n",
      "store 1543 -> 0.9478\n",
      "store 1544 -> 0.9169\n",
      "store 1545 -> 0.7995\n",
      "store 1546 -> 0.6535\n",
      "store 1547 -> 0.9014\n",
      "store 1548 -> 0.9358\n",
      "store 1549 -> 0.9149\n",
      "store 1550 -> 0.9466\n",
      "store 1551 -> 0.8594\n",
      "store 1552 -> 0.9254\n",
      "store 1553 -> 0.9270\n",
      "store 1554 -> 0.9423\n",
      "store 1555 -> 0.8483\n",
      "store 1556 -> 0.7750\n",
      "store 1557 -> 0.9186\n",
      "store 1558 -> 0.8059\n",
      "store 1559 -> 0.7955\n",
      "store 1560 -> 0.8787\n",
      "store 1561 -> 0.9196\n",
      "store 1562 -> 0.9383\n",
      "store 1563 -> 0.9339\n",
      "store 1564 -> 0.9045\n",
      "store 1565 -> 0.9383\n",
      "store 1566 -> 0.9229\n",
      "store 1567 -> 0.9144\n",
      "store 1568 -> 0.8627\n",
      "store 1569 -> 0.9311\n",
      "store 1570 -> 0.9388\n",
      "store 1571 -> 0.9071\n",
      "store 1572 -> 0.9361\n",
      "store 1573 -> 0.9009\n",
      "store 1574 -> 0.9059\n",
      "store 1575 -> 0.8703\n",
      "store 1576 -> 0.9182\n",
      "store 1577 -> 0.8908\n",
      "store 1578 -> 0.8954\n",
      "store 1579 -> 0.9046\n",
      "store 1580 -> 0.9324\n",
      "store 1581 -> 0.6548\n",
      "store 1582 -> 0.9408\n",
      "store 1583 -> 0.8299\n",
      "store 1584 -> 0.8152\n",
      "store 1585 -> 0.8802\n",
      "store 1586 -> 0.9121\n",
      "store 1587 -> 0.9454\n",
      "store 1588 -> 0.9373\n",
      "store 1589 -> 0.9179\n",
      "store 1590 -> 0.9409\n",
      "store 1591 -> 0.9128\n",
      "store 1592 -> 0.9407\n",
      "store 1593 -> 0.6659\n",
      "store 1594 -> 0.3133\n",
      "store 1595 -> 0.8604\n",
      "store 1596 -> 0.9369\n",
      "store 1597 -> 0.9511\n",
      "store 1598 -> 0.9123\n",
      "store 1599 -> 0.7670\n",
      "store 1600 -> 0.9203\n",
      "store 1601 -> 0.8931\n",
      "store 1602 -> 0.9043\n",
      "store 1603 -> 0.9537\n",
      "store 1604 -> 0.9237\n",
      "store 1605 -> 0.8784\n",
      "store 1606 -> 0.9246\n",
      "store 1607 -> 0.9116\n",
      "store 1608 -> 0.8813\n",
      "store 1609 -> 0.9173\n",
      "store 1610 -> 0.8823\n",
      "store 1611 -> 0.8988\n",
      "store 1612 -> 0.9027\n",
      "store 1613 -> 0.9049\n",
      "store 1614 -> 0.9315\n",
      "store 1615 -> 0.8412\n",
      "store 1616 -> 0.8485\n",
      "store 1617 -> 0.9359\n",
      "store 1618 -> 0.8908\n",
      "store 1619 -> 0.8263\n",
      "store 1620 -> 0.8841\n",
      "store 1621 -> 0.9138\n",
      "store 1622 -> 0.9120\n",
      "store 1623 -> 0.8096\n",
      "store 1624 -> 0.9368\n",
      "store 1625 -> 0.9228\n",
      "store 1626 -> 0.9378\n",
      "store 1627 -> 0.8868\n",
      "store 1628 -> 0.9275\n",
      "store 1629 -> 0.8964\n",
      "store 1630 -> 0.7292\n",
      "store 1631 -> 0.8787\n",
      "store 1632 -> 0.9279\n",
      "store 1633 -> 0.9210\n",
      "store 1634 -> 0.8619\n",
      "store 1635 -> 0.8991\n",
      "store 1636 -> 0.9190\n",
      "store 1637 -> 0.9314\n",
      "store 1638 -> 0.9482\n",
      "store 1639 -> 0.9355\n",
      "store 1640 -> 0.8398\n",
      "store 1641 -> 0.9383\n",
      "store 1642 -> 0.8933\n",
      "store 1643 -> 0.8433\n",
      "store 1644 -> 0.9426\n",
      "store 1645 -> 0.9234\n",
      "store 1646 -> 0.8794\n",
      "store 1647 -> 0.9251\n",
      "store 1648 -> 0.8722\n",
      "store 1649 -> 0.9108\n",
      "store 1650 -> 0.9000\n",
      "store 1651 -> 0.8830\n",
      "store 1652 -> 0.8288\n",
      "store 1653 -> 0.4674\n",
      "store 1654 -> 0.9043\n",
      "store 1655 -> 0.9299\n",
      "store 1656 -> 0.9453\n",
      "store 1657 -> 0.9467\n",
      "store 1658 -> 0.8677\n",
      "store 1659 -> 0.9246\n",
      "store 1660 -> 0.9010\n",
      "store 1661 -> 0.9622\n",
      "store 1662 -> 0.9435\n",
      "store 1663 -> 0.9333\n",
      "store 1664 -> 0.9356\n",
      "store 1665 -> 0.6370\n",
      "store 1666 -> 0.8931\n",
      "store 1667 -> 0.9123\n",
      "store 1668 -> 0.9091\n",
      "store 1669 -> 0.8807\n",
      "store 1670 -> 0.9174\n",
      "store 1671 -> 0.5504\n",
      "store 1672 -> 0.9139\n",
      "store 1673 -> 0.9589\n",
      "store 1674 -> 0.9517\n",
      "store 1675 -> 0.9152\n",
      "store 1676 -> 0.9053\n",
      "store 1677 -> 0.9367\n",
      "store 1678 -> 0.9387\n",
      "store 1679 -> 0.9261\n",
      "store 1680 -> 0.8994\n",
      "store 1681 -> 0.9334\n",
      "store 1682 -> 0.9130\n",
      "store 1683 -> 0.9103\n",
      "store 1684 -> 0.9546\n",
      "store 1685 -> 0.8742\n",
      "store 1686 -> 0.9318\n",
      "store 1687 -> 0.9136\n",
      "store 1688 -> 0.8718\n",
      "store 1689 -> 0.9449\n",
      "store 1690 -> 0.8879\n",
      "store 1691 -> 0.9334\n",
      "store 1692 -> 0.8392\n",
      "store 1693 -> 0.8977\n",
      "store 1694 -> 0.9329\n",
      "store 1695 -> 0.9486\n",
      "store 1696 -> 0.9385\n",
      "store 1697 -> 0.9121\n",
      "store 1698 -> 0.9460\n",
      "store 1699 -> 0.9408\n",
      "store 1700 -> 0.9173\n",
      "store 1701 -> 0.9384\n",
      "store 1702 -> 0.8626\n",
      "store 1703 -> 0.9172\n",
      "store 1704 -> 0.8674\n",
      "store 1705 -> 0.9369\n",
      "store 1706 -> 0.9388\n",
      "store 1707 -> 0.9321\n",
      "store 1708 -> 0.9452\n",
      "store 1709 -> 0.9013\n",
      "store 1710 -> 0.9182\n",
      "store 1711 -> 0.7911\n",
      "store 1712 -> 0.9139\n",
      "store 1713 -> 0.9413\n",
      "store 1714 -> 0.9121\n",
      "store 1715 -> 0.9303\n",
      "store 1716 -> 0.8741\n",
      "store 1717 -> 0.8552\n",
      "store 1718 -> 0.8665\n",
      "store 1719 -> 0.9210\n",
      "store 1720 -> 0.8655\n",
      "store 1721 -> 0.9014\n",
      "store 1722 -> 0.8979\n",
      "store 1723 -> 0.9084\n",
      "store 1724 -> 0.8853\n",
      "store 1725 -> 0.9412\n",
      "store 1726 -> 0.9428\n",
      "store 1727 -> 0.8941\n",
      "store 1728 -> 0.8981\n",
      "store 1729 -> 0.7409\n",
      "store 1730 -> 0.9144\n",
      "store 1731 -> 0.9103\n",
      "store 1732 -> 0.9043\n",
      "store 1733 -> 0.8500\n",
      "store 1734 -> 0.9106\n",
      "store 1735 -> 0.9003\n",
      "store 1736 -> 0.9395\n",
      "store 1737 -> 0.8548\n",
      "store 1738 -> 0.9471\n",
      "store 1739 -> 0.9302\n",
      "store 1740 -> 0.9235\n",
      "store 1741 -> 0.9481\n",
      "store 1742 -> 0.9171\n",
      "store 1743 -> 0.9139\n",
      "store 1744 -> 0.9444\n",
      "store 1745 -> 0.9249\n",
      "store 1746 -> 0.8766\n",
      "store 1747 -> 0.9137\n",
      "store 1748 -> 0.9149\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "scores = {}\n",
    "predictions = defaultdict(dict)\n",
    "store_pred = {}\n",
    "shopping_center_ids = [1129,1267,1280,1307,1330,1339,1357,1387,1676]\n",
    "ids = train_df.StoreID.unique()\n",
    "for storeid in ids:\n",
    "    # define the model\n",
    "    \n",
    "    if storeid not in shopping_center_ids:\n",
    "        model1 = Lasso(alpha=50)\n",
    "        model2 = Ridge(alpha=1)\n",
    "        model3 =XGBRegressor(max_depth=4,\n",
    "                            gamma=0.05, \n",
    "                            learning_rate=0.05, \n",
    "                                 n_estimators=500,\n",
    "                                 subsample=0.3, silent=1,\n",
    "                                 random_state =7, nthread = -1)\n",
    "\n",
    "        model4 = GradientBoostingRegressor(n_estimators=500, learning_rate=0.05,\n",
    "                                       max_depth=2,loss='lad',random_state =5)\n",
    "\n",
    "\n",
    "        model = AveragingModels(models = (model1,model2,model3,model4))\n",
    "\n",
    "\n",
    "#     #model for shopping centers only -> makes lanzi error bigger althoug r^2 is lower..TOO BAD!\n",
    "#     if storeid in shopping_center_ids:\n",
    "#         model_shop1 = GradientBoostingRegressor(n_estimators=500, learning_rate=0.05,\n",
    "#                                     max_depth=2,loss='lad',random_state =5)\n",
    "#         model_shop2 =XGBRegressor()\n",
    "#         model= AveragingModels(models = (model_shop1,model_shop2))\n",
    "\n",
    "\n",
    "    # split the dataset\n",
    "    train = train_df[train_df.StoreID == storeid]\n",
    "    \n",
    "    x_train, y_train, x_test, y_test =\\\n",
    "    split_dataset_bymonth(2018, [1,2], train)\n",
    "    \n",
    "    # train the model with the training set\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    \n",
    "    # scoring\n",
    "    scores[storeid] = r2_score(y_test, model.predict(x_test))\n",
    "    print('store {} -> {:.4f}'.format(storeid, scores[storeid]))\n",
    "    store_pred[storeid] = scores[storeid]\n",
    "    # predict the test set with the trained model\n",
    "    for month in x_test.month.unique():\n",
    "        # get daily predictions for each month in the test set\n",
    "        month_prediction =model.predict(x_test[x_test.month == month])\n",
    "        month_actual = y_test.loc[x_test[x_test.month == month].index].values\n",
    "        \n",
    "        # store the monthly mean of the test set\n",
    "        predictions[storeid][month] = {\n",
    "            'predicted': np.mean(month_prediction),\n",
    "            'actual': np.mean(month_actual)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import operator\n",
    "sorted_store_pred = sorted(store_pred.items(), key=operator.itemgetter(1))\n",
    "# sorted_store_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of regions\n",
    "R = sorted(train_df_orig.Region.unique().astype(int))\n",
    "# set of predicted months\n",
    "months = [key for key, value in predictions[1000].items()]\n",
    "# set of stores by region\n",
    "dict_store_byRegion = train_df_orig[['Region', 'StoreID']].drop_duplicates()\\\n",
    ".set_index('StoreID').groupby('Region').groups\n",
    "\n",
    "# region_error inputs:\n",
    "#\n",
    "# int region = a number from 0 to 11\n",
    "# dict predictions = {\n",
    "#     int storeID: {\n",
    "#         int month: {\n",
    "#             str 'predicted': float,\n",
    "#             str 'actual': float\n",
    "#         }\n",
    "#         ...\n",
    "#     }\n",
    "#     ...\n",
    "# }\n",
    "def region_error(region, predictions):    \n",
    "    num = 0\n",
    "    den = 0\n",
    "    for store in dict_store_byRegion[str(region)]:\n",
    "        for month in months:\n",
    "            predicted = predictions[store][month]['predicted']\n",
    "            actual = predictions[store][month]['actual']\n",
    "            \n",
    "            num += abs(actual - predicted)\n",
    "            den += actual\n",
    "    \n",
    "    return num/den\n",
    "    \n",
    "# total_error input:\n",
    "\n",
    "# region_errors = [0.3, 0.5, ... ]\n",
    "def total_error(region_errors):\n",
    "    return sum(region_errors)/len(region_errors)\n",
    "\n",
    "def lanzi_error(predictions):\n",
    "    region_errors = []\n",
    "    for r in R:\n",
    "        region_errors.append(region_error(r, predictions))\n",
    "    \n",
    "    return total_error(region_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lanzi error: 0.041999104189949205\n"
     ]
    }
   ],
   "source": [
    "print('Lanzi error: {}'.format(lanzi_error(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting R^2 Error for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(\"say -v \"+'Alice'+\"Lanzi Merda\")\n",
    "# trace1 = go.Bar(\n",
    "#             x=prediction_result['Training_dates'],\n",
    "#             y=prediction_result['Scores'],\n",
    "#             name='R^2 per region'\n",
    "#     )\n",
    "\n",
    "# trace2 = go.Scatter(x=prediction_result['Training_dates'],\n",
    "#                     y=[np.asarray(prediction_result['Scores']).mean()]*len(prediction_result['Scores']),\n",
    "#                     line = dict(color=('rgb(0, 0, 0)'),\n",
    "#                     width=2, dash='dash',shape='hv'),\n",
    "#                     name = 'Mean'\n",
    "#                    )\n",
    "\n",
    "# layout = go.Layout(\n",
    "#     title= 'R^2',\n",
    "#     yaxis=dict(\n",
    "#         range=[0,1]\n",
    "#     )\n",
    "# )\n",
    "# data=[trace1,trace2]\n",
    "# fig = go.Figure(data=data, layout=layout)\n",
    "# iplot(fig, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted vs Real for march17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regions=list(['Region_'+str(i) for i in range(0,11)])\n",
    "# data_real=[]\n",
    "# data_pred=[]\n",
    "# for region in regions:\n",
    "#     region_df_real = prediction_result['Training_df'][0][prediction_result['Training_df'][0][region]==1]\n",
    "#     region_df_pred = prediction_result['Predicted_df'][0][prediction_result['Predicted_df'][0][region]==1]\n",
    "#     sales_real = region_df_real['NumberOfSales'].sum()\n",
    "#     sales_pred= region_df_pred['NumberOfSales'].sum()\n",
    "#     data_real.append(sales_real)\n",
    "#     data_pred.append(sales_pred)\n",
    "\n",
    "# trace_r=go.Bar(x=np.arange(0,12),\n",
    "#                 y=data_real,\n",
    "#                 name='Real sales'\n",
    "#                 )\n",
    "\n",
    "# trace_p=go.Bar(x=np.arange(0,12),\n",
    "#                  y=data_pred,\n",
    "#                  name='Preicted Sales')\n",
    "\n",
    "# data_tot = [trace_r, trace_p]\n",
    "# layout = go.Layout(\n",
    "#     barmode='group',\n",
    "#     title='Real vs Predicted sales per region in March17',\n",
    "#     yaxis=dict(title='Sales'),\n",
    "#     xaxis=dict(title='Region')\n",
    "# )\n",
    "\n",
    "# fig = go.Figure(data=data_tot, layout=layout)\n",
    "# iplot(fig, filename='Population info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
