{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(523021, 73)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn import metrics\n",
    "import  plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import os\n",
    "import colorlover  as cl\n",
    "from tqdm import tqdm\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import skew\n",
    "\n",
    "\n",
    "# environment settings\n",
    "data_path_out = 'Data/output/'\n",
    "\n",
    "#hack to avoid showing deprecationg warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "# Deserialize previously saved data from \"preprocessing\"\n",
    "with open(data_path_out+'train_pp.obj', 'rb') as train_pp:\n",
    "    train_df = pickle.load(train_pp)\n",
    "\n",
    "#Dummies\n",
    "train_df = pd.get_dummies(train_df)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that all closed stores don't have sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StoreID</th>\n",
       "      <th>Date</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>IsOpen</th>\n",
       "      <th>HasPromotions</th>\n",
       "      <th>NearestCompetitor</th>\n",
       "      <th>Region_AreaKM2</th>\n",
       "      <th>Region_GDP</th>\n",
       "      <th>Region_PopulationK</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>...</th>\n",
       "      <th>Events_Rain-Hail</th>\n",
       "      <th>Events_Rain-Hail-Thunderstorm</th>\n",
       "      <th>Events_Rain-Snow</th>\n",
       "      <th>Events_Rain-Snow-Hail</th>\n",
       "      <th>Events_Rain-Snow-Hail-Thunderstorm</th>\n",
       "      <th>Events_Rain-Snow-Thunderstorm</th>\n",
       "      <th>Events_Rain-Thunderstorm</th>\n",
       "      <th>Events_Snow</th>\n",
       "      <th>Events_Snow-Hail</th>\n",
       "      <th>Events_Thunderstorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [StoreID, Date, IsHoliday, IsOpen, HasPromotions, NearestCompetitor, Region_AreaKM2, Region_GDP, Region_PopulationK, CloudCover, Max_Dew_PointC, Max_Humidity, Max_Sea_Level_PressurehPa, Max_TemperatureC, Max_VisibilityKm, Max_Wind_SpeedKm_h, Mean_Dew_PointC, Mean_Humidity, Mean_Sea_Level_PressurehPa, Mean_TemperatureC, Mean_VisibilityKm, Mean_Wind_SpeedKm_h, Min_Dew_PointC, Min_Humidity, Min_Sea_Level_PressurehPa, Min_TemperatureC, Min_VisibilitykM, Precipitationmm, WindDirDegrees, Hol_and_open, Region_PD, NumberOfSales, NumberOfCustomers, StoreType_Hyper Market, StoreType_Standard Market, StoreType_Super Market, StoreType_Shopping Center, AssortmentType_General, AssortmentType_With Non-Food Department, AssortmentType_With Fish Department, Region_0, Region_1, Region_10, Region_2, Region_3, Region_4, Region_5, Region_7, Region_9, Region_6, Region_8, Events_Fog, Events_Fog-Rain, Events_Fog-Rain-Hail, Events_Fog-Rain-Hail-Thunderstorm, Events_Fog-Rain-Snow, Events_Fog-Rain-Snow-Hail, Events_Fog-Rain-Thunderstorm, Events_Fog-Snow, Events_Fog-Snow-Hail, Events_Fog-Thunderstorm, Events_Normal, Events_Rain, Events_Rain-Hail, Events_Rain-Hail-Thunderstorm, Events_Rain-Snow, Events_Rain-Snow-Hail, Events_Rain-Snow-Hail-Thunderstorm, Events_Rain-Snow-Thunderstorm, Events_Rain-Thunderstorm, Events_Snow, Events_Snow-Hail, Events_Thunderstorm]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 73 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[(train_df['IsOpen'] == False) & (train_df['NumberOfSales']>0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['day'] = train_df.Date.dt.day\n",
    "train_df['month'] = train_df.Date.dt.month\n",
    "train_df['year'] = train_df.Date.dt.year\n",
    "train_df['WeekOfYear'] = train_df.Date.dt.week\n",
    "train_df['DaysInMonth'] = train_df.Date.dt.daysinmonth\n",
    "train_df['DayOfYear'] = train_df.Date.dt.dayofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New sales features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def num_of_features(regional_week_year,week,year,column_of_interest):\n",
    "    num_holidays=0\n",
    "\n",
    "    if week ==1:\n",
    "        week_before=[52,year-1]\n",
    "        week_after=[2,year]\n",
    "    if week == 52:\n",
    "        week_after=[1,year+1]\n",
    "        week_before=[51,year]\n",
    "    if (week>1) & (week<52):\n",
    "        week_before=[week-1,year]\n",
    "        week_after=[week+1,year]\n",
    "    \n",
    "    before_df = regional_week_year[(regional_week_year['WeekOfYear']==week_before[0])&\n",
    "                                  (regional_week_year['year']==week_before[1])]\n",
    "    \n",
    "    after_df = regional_week_year[(regional_week_year['WeekOfYear']==week_after[0])&\n",
    "                                  (regional_week_year['year']==week_after[1])]\n",
    "    this_df = regional_week_year[(regional_week_year['WeekOfYear']==week)&\n",
    "                                 (regional_week_year['year']==year)]\n",
    "    \n",
    "    num_ago = before_df[before_df[column_of_interest]][column_of_interest].sum()\n",
    "    num_next = after_df[after_df[column_of_interest]][column_of_interest].sum()\n",
    "    num_this = this_df[this_df[column_of_interest]][column_of_interest].sum()\n",
    "    \n",
    "    return num_ago,num_next,num_this\n",
    "\n",
    "def create_new_features(before,current,after,column_of_interest):\n",
    "    train_df[before] = 0\n",
    "    train_df[current]=0\n",
    "    train_df[after] = 0\n",
    "\n",
    "    region_list= [\"Region_\"+str(d) for d in range(0,11)]\n",
    "    for region in tqdm(region_list):\n",
    "        curr_region = train_df[train_df[region]==1]\n",
    "\n",
    "        #get all valid dates of that region\n",
    "        regional_week_year=curr_region[['WeekOfYear','year',column_of_interest]]\n",
    "\n",
    "        #get all store ids of that region\n",
    "        regional_stores=len(curr_region['StoreID'].unique())\n",
    "\n",
    "        week_year_list =regional_week_year[['WeekOfYear','year']].drop_duplicates().values.tolist()\n",
    "\n",
    "        for date in week_year_list:\n",
    "            num_ago,num_next,num_this = num_of_features(regional_week_year,\n",
    "                                                        date[0],\n",
    "                                                        date[1],\n",
    "                                                        column_of_interest)\n",
    "\n",
    "            train_df.at[((train_df['WeekOfYear']==date[0])&\n",
    "                         (train_df['year']==date[1])),before]=int(num_ago/regional_stores)\n",
    "            train_df.at[((train_df['WeekOfYear']==date[0])&\n",
    "                         (train_df['year']==date[1])),after]=int(num_next/regional_stores)\n",
    "            train_df.at[((train_df['WeekOfYear']==date[0])&\n",
    "                         (train_df['year']==date[1])),current]=int(num_this/regional_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [01:32<00:00,  8.44s/it]\n",
      "100%|██████████| 11/11 [01:36<00:00,  8.77s/it]\n"
     ]
    }
   ],
   "source": [
    "create_new_features('HolidaysWeekBefore','HolidaysWeekCurrent','HolidaysWeekAfter','IsHoliday')\n",
    "create_new_features('PromoWeekBefore','PromoWeekCurrent','PromoWeekAfter','HasPromotions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop NumberOfCustomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df =train_df.drop('NumberOfCustomers',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop closed stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_closed = (train_df['IsOpen']==False)\n",
    "# train_df=train_df[~mask_closed]\n",
    "# train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dates = pd.DatetimeIndex(train_df['Date'])\n",
    "month_dict = { d.strftime(\"%B%Y\") :datetime.strptime(d.strftime('%m-%Y'),'%m-%Y') for d in all_dates}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA -> useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0885402  0.14312627 0.19039511 0.23353448 0.27249089 0.3092255\n",
      " 0.34054463 0.36782221 0.39163594 0.41513407 0.43701514 0.45759482\n",
      " 0.47674043 0.49459287 0.51230881 0.52901529 0.54466006 0.5600574\n",
      " 0.5750247  0.58932052 0.60286445 0.61623207 0.62946464 0.64258977\n",
      " 0.6553859  0.66780464 0.6801545  0.69239363 0.70459161 0.71675621\n",
      " 0.72888809 0.7409871  0.75306151 0.76511292 0.77713714 0.78912656\n",
      " 0.80109447 0.81289145 0.82454647 0.83612541 0.84762407 0.85891663\n",
      " 0.86910631 0.87902717 0.88835199 0.89729907 0.90609942 0.91444323\n",
      " 0.92250559 0.93025305 0.93763962 0.94446129 0.95101731 0.95748109\n",
      " 0.96349962 0.96903134 0.97384288 0.97827558 0.98252482 0.98629139\n",
      " 0.98967567 0.99278265 0.99448472 0.9959177  0.99718424 0.99804833\n",
      " 0.99866456 0.99909162 0.9994921  0.99969113 0.99981823 0.99989784\n",
      " 0.99997238 0.99999988 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_df2 = train_df.drop('Date',axis=1)\n",
    "sc= StandardScaler()\n",
    "train_scaled = sc.fit_transform(train_df2.values)\n",
    "cov_mat = np.cov(train_scaled.T)\n",
    "eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n",
    "tot = sum(eigen_vals)\n",
    "var_exp = [(i/tot) for i in sorted(eigen_vals,reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print(cum_var_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Method Training and predicting one-hold out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def monthly_training(training_interval=['03-2017','02-2018'],\n",
    "                     verbose=False,\n",
    "                     regressor=RandomForestRegressor(n_estimators=50,n_jobs=-1)):\n",
    "    \n",
    "    init_date=datetime.strptime(training_interval[0],'%m-%Y')\n",
    "    end_date =datetime.strptime(training_interval[1],'%m-%Y')\n",
    "    \n",
    "    month_scores = []\n",
    "    y_test_list = []\n",
    "    predicted_list= []\n",
    "    predicted_df_list = []\n",
    "    training_months = []\n",
    "    training_df_list = []\n",
    "    for month_name, date in month_dict.items():\n",
    "\n",
    "        if (date >= init_date) & (date<= end_date) :\n",
    "                if verbose== True:\n",
    "                    print(\"Doing month\",month_name)\n",
    "                    \n",
    "                training_months.append(month_name)\n",
    "                mask = ((train_df['month']==date.month) & (train_df['year']==date.year))\n",
    "                test = train_df[mask]\n",
    "                train = train_df[~mask]\n",
    "                \n",
    "                y_train = train.NumberOfSales\n",
    "                X_train = train.drop('NumberOfSales',axis = 1)\n",
    "\n",
    "                y_test = test.NumberOfSales\n",
    "                X_test = test.drop('NumberOfSales',axis = 1)\n",
    "\n",
    "                X_train = X_train.drop('Date',axis=1)\n",
    "                X_test = X_test.drop('Date',axis=1)\n",
    "                \n",
    "                #slightly better with this scaler\n",
    "                scaler = RobustScaler()\n",
    "                X_train_scaled=scaler.fit(X_train).transform(X_train)\n",
    "                X_test_scaled=scaler.transform(X_test)\n",
    "                \n",
    "                reg =  regressor.fit(X_train_scaled,y_train)\n",
    "                \n",
    "                current_score = reg.score(X_test_scaled,y_test)\n",
    "                current_prediction = reg.predict(X_test_scaled)\n",
    "                month_scores.append(current_score)\n",
    "                predicted_list.append(current_prediction)\n",
    "                y_test_list.append(y_test)\n",
    "                \n",
    "                if verbose == True:\n",
    "                    print(\"Month {} has shape {}\\n\\t\".format(month_name,test.shape))\n",
    "                    print(\"-Score {}\".format(current_score))\n",
    "                \n",
    "                \n",
    "                real_df = train_df.copy()\n",
    "                month_test_df = train_df[mask]\n",
    "                month_train_df= train_df[~mask]\n",
    "\n",
    "                month_test_df= month_test_df.drop('NumberOfSales',axis=1)\n",
    "                prediction_=pd.Series(current_prediction)\n",
    "                month_test_df['NumberOfSales']=prediction_.values.astype(int)\n",
    "                predicted_df = pd.concat([month_test_df,month_train_df]).reset_index()\n",
    "                predicted_df= predicted_df[list(train_df.columns.values)]\n",
    "                \n",
    "                predicted_df_list.append(predicted_df)\n",
    "                training_df_list.append(train)\n",
    "                \n",
    "    return {\n",
    "        'Scores' : month_scores,\n",
    "        'Real' : y_test_list,\n",
    "        'Predictions' : predicted_list,\n",
    "        'Training_dates': training_months,\n",
    "        'Training_df' : training_df_list,\n",
    "        'Predicted_df' : predicted_df_list\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing month March2017\n",
      "Month March2017 has shape (23219, 84)\n",
      "\t\n",
      "-Score 0.8958202620311949\n",
      "Doing month April2017\n",
      "Month April2017 has shape (22470, 84)\n",
      "\t\n",
      "-Score 0.9096298524271111\n",
      "Doing month May2017\n",
      "Month May2017 has shape (23219, 84)\n",
      "\t\n",
      "-Score 0.9305414665166207\n",
      "Doing month June2017\n",
      "Month June2017 has shape (22470, 84)\n",
      "\t\n",
      "-Score 0.915755111200066\n",
      "Doing month July2017\n",
      "Month July2017 has shape (19719, 84)\n",
      "\t\n",
      "-Score 0.8886200352218604\n",
      "Doing month August2017\n",
      "Month August2017 has shape (19344, 84)\n",
      "\t\n",
      "-Score 0.8838095730903466\n",
      "Doing month September2017\n",
      "Month September2017 has shape (18720, 84)\n",
      "\t\n",
      "-Score 0.9018718902305893\n",
      "Doing month October2017\n",
      "Month October2017 has shape (19344, 84)\n",
      "\t\n",
      "-Score 0.9325286579899239\n",
      "Doing month November2017\n",
      "Month November2017 has shape (18720, 84)\n",
      "\t\n",
      "-Score 0.9185736479452733\n",
      "Doing month December2017\n",
      "Month December2017 has shape (19344, 84)\n",
      "\t\n",
      "-Score 0.8491405983859167\n",
      "Doing month January2018\n",
      "Month January2018 has shape (22844, 84)\n",
      "\t\n",
      "-Score 0.9041948773385816\n",
      "Doing month February2018\n",
      "Month February2018 has shape (20972, 84)\n",
      "\t\n",
      "-Score 0.8516810813182207\n"
     ]
    }
   ],
   "source": [
    "reg = RandomForestRegressor(n_estimators=50,n_jobs=-1\n",
    "                           )\n",
    "prediction_result = monthly_training(verbose=True,\n",
    "                                     training_interval=['03-2017','02-2018'],\n",
    "                                     regressor = reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2  Method : Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "y = train_df.NumberOfSales\n",
    "X_train = train_df.drop('NumberOfSales',axis = 1)\n",
    "X_train = train_df.drop('Date',axis = 1)\n",
    "X_scaled=scaler.fit_transform(X_train)\n",
    "kf = KFold(5, shuffle=True, random_state=42).get_n_splits(X_scaled)\n",
    "rf = RandomForestRegressor(n_estimators=50,n_jobs=-1)\n",
    "r2_rf= cross_val_score(rf, X_scaled, y, scoring=\"r2\", cv = kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5-fold crossvalidation R2 of Random Forest is 1.0000 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "print(\"The 5-fold crossvalidation R2 of Random Forest is {:.4f} +/- {:.3f}\".format(r2_rf.mean(),r2_rf.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting R^2 Error for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "R^2 per region",
         "type": "bar",
         "x": [
          "March2017",
          "April2017",
          "May2017",
          "June2017",
          "July2017",
          "August2017",
          "September2017",
          "October2017",
          "November2017",
          "December2017",
          "January2018",
          "February2018"
         ],
         "y": [
          0.8958202620311949,
          0.9096298524271111,
          0.9305414665166207,
          0.915755111200066,
          0.8886200352218604,
          0.8838095730903466,
          0.9018718902305893,
          0.9325286579899239,
          0.9185736479452733,
          0.8491405983859167,
          0.9041948773385816,
          0.8516810813182207
         ]
        },
        {
         "line": {
          "color": "rgb(0, 0, 0)",
          "dash": "dash",
          "shape": "hv",
          "width": 2
         },
         "name": "Mean",
         "type": "scatter",
         "x": [
          "March2017",
          "April2017",
          "May2017",
          "June2017",
          "July2017",
          "August2017",
          "September2017",
          "October2017",
          "November2017",
          "December2017",
          "January2018",
          "February2018"
         ],
         "y": [
          0.8985139211413088,
          0.8985139211413088,
          0.8985139211413088,
          0.8985139211413088,
          0.8985139211413088,
          0.8985139211413088,
          0.8985139211413088,
          0.8985139211413088,
          0.8985139211413088,
          0.8985139211413088,
          0.8985139211413088,
          0.8985139211413088
         ]
        }
       ],
       "layout": {
        "title": "R^2",
        "yaxis": {
         "range": [
          0,
          1
         ]
        }
       }
      },
      "text/html": [
       "<div id=\"e720e633-1982-481d-85aa-d3a45e79ab1e\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"e720e633-1982-481d-85aa-d3a45e79ab1e\", [{\"type\": \"bar\", \"x\": [\"March2017\", \"April2017\", \"May2017\", \"June2017\", \"July2017\", \"August2017\", \"September2017\", \"October2017\", \"November2017\", \"December2017\", \"January2018\", \"February2018\"], \"y\": [0.8958202620311949, 0.9096298524271111, 0.9305414665166207, 0.915755111200066, 0.8886200352218604, 0.8838095730903466, 0.9018718902305893, 0.9325286579899239, 0.9185736479452733, 0.8491405983859167, 0.9041948773385816, 0.8516810813182207], \"name\": \"R^2 per region\"}, {\"type\": \"scatter\", \"x\": [\"March2017\", \"April2017\", \"May2017\", \"June2017\", \"July2017\", \"August2017\", \"September2017\", \"October2017\", \"November2017\", \"December2017\", \"January2018\", \"February2018\"], \"y\": [0.8985139211413088, 0.8985139211413088, 0.8985139211413088, 0.8985139211413088, 0.8985139211413088, 0.8985139211413088, 0.8985139211413088, 0.8985139211413088, 0.8985139211413088, 0.8985139211413088, 0.8985139211413088, 0.8985139211413088], \"line\": {\"color\": \"rgb(0, 0, 0)\", \"width\": 2, \"dash\": \"dash\", \"shape\": \"hv\"}, \"name\": \"Mean\"}], {\"title\": \"R^2\", \"yaxis\": {\"range\": [0, 1]}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"e720e633-1982-481d-85aa-d3a45e79ab1e\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"e720e633-1982-481d-85aa-d3a45e79ab1e\", [{\"type\": \"bar\", \"x\": [\"March2017\", \"April2017\", \"May2017\", \"June2017\", \"July2017\", \"August2017\", \"September2017\", \"October2017\", \"November2017\", \"December2017\", \"January2018\", \"February2018\"], \"y\": [0.8958202620311949, 0.9096298524271111, 0.9305414665166207, 0.915755111200066, 0.8886200352218604, 0.8838095730903466, 0.9018718902305893, 0.9325286579899239, 0.9185736479452733, 0.8491405983859167, 0.9041948773385816, 0.8516810813182207], \"name\": \"R^2 per region\"}, {\"type\": \"scatter\", \"x\": [\"March2017\", \"April2017\", \"May2017\", \"June2017\", \"July2017\", \"August2017\", \"September2017\", \"October2017\", \"November2017\", \"December2017\", \"January2018\", \"February2018\"], \"y\": [0.8985139211413088, 0.8985139211413088, 0.8985139211413088, 0.8985139211413088, 0.8985139211413088, 0.8985139211413088, 0.8985139211413088, 0.8985139211413088, 0.8985139211413088, 0.8985139211413088, 0.8985139211413088, 0.8985139211413088], \"line\": {\"color\": \"rgb(0, 0, 0)\", \"width\": 2, \"dash\": \"dash\", \"shape\": \"hv\"}, \"name\": \"Mean\"}], {\"title\": \"R^2\", \"yaxis\": {\"range\": [0, 1]}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.system(\"say -v \"+'Alice'+\" Ho fatto\")\n",
    "trace1 = go.Bar(\n",
    "            x=prediction_result['Training_dates'],\n",
    "            y=prediction_result['Scores'],\n",
    "            name='R^2 per region'\n",
    "    )\n",
    "\n",
    "trace2 = go.Scatter(x=prediction_result['Training_dates'],\n",
    "                    y=[np.asarray(prediction_result['Scores']).mean()]*len(prediction_result['Scores']),\n",
    "                    line = dict(color=('rgb(0, 0, 0)'),\n",
    "                    width=2, dash='dash',shape='hv'),\n",
    "                    name = 'Mean'\n",
    "                   )\n",
    "\n",
    "layout = go.Layout(\n",
    "    title= 'R^2',\n",
    "    yaxis=dict(\n",
    "        range=[0,1]\n",
    "    )\n",
    ")\n",
    "data=[trace1,trace2]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted vs Real for march17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "Real sales",
         "type": "bar",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11
         ],
         "y": [
          154686740,
          63523918,
          246057524,
          313946172,
          60787088,
          132197718,
          88189681,
          169196949,
          67000796,
          483214853,
          251681463
         ]
        },
        {
         "name": "Preicted Sales",
         "type": "bar",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11
         ],
         "y": [
          161408319,
          66268304,
          261341351,
          327854027,
          63496169,
          138002266,
          92151703,
          176669913,
          69977947,
          504978608,
          262566905
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "title": "Real vs Predicted sales per region in March17",
        "xaxis": {
         "title": "Region"
        },
        "yaxis": {
         "title": "Sales"
        }
       }
      },
      "text/html": [
       "<div id=\"5e12edbd-3c65-456b-9478-feb16bb0e0b6\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"5e12edbd-3c65-456b-9478-feb16bb0e0b6\", [{\"type\": \"bar\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"y\": [154686740, 63523918, 246057524, 313946172, 60787088, 132197718, 88189681, 169196949, 67000796, 483214853, 251681463], \"name\": \"Real sales\"}, {\"type\": \"bar\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"y\": [161408319, 66268304, 261341351, 327854027, 63496169, 138002266, 92151703, 176669913, 69977947, 504978608, 262566905], \"name\": \"Preicted Sales\"}], {\"barmode\": \"group\", \"title\": \"Real vs Predicted sales per region in March17\", \"yaxis\": {\"title\": \"Sales\"}, \"xaxis\": {\"title\": \"Region\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"5e12edbd-3c65-456b-9478-feb16bb0e0b6\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"5e12edbd-3c65-456b-9478-feb16bb0e0b6\", [{\"type\": \"bar\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"y\": [154686740, 63523918, 246057524, 313946172, 60787088, 132197718, 88189681, 169196949, 67000796, 483214853, 251681463], \"name\": \"Real sales\"}, {\"type\": \"bar\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"y\": [161408319, 66268304, 261341351, 327854027, 63496169, 138002266, 92151703, 176669913, 69977947, 504978608, 262566905], \"name\": \"Preicted Sales\"}], {\"barmode\": \"group\", \"title\": \"Real vs Predicted sales per region in March17\", \"yaxis\": {\"title\": \"Sales\"}, \"xaxis\": {\"title\": \"Region\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regions=list(['Region_'+str(i) for i in range(0,11)])\n",
    "data_real=[]\n",
    "data_pred=[]\n",
    "for region in regions:\n",
    "    region_df_real = prediction_result['Training_df'][0][prediction_result['Training_df'][0][region]==1]\n",
    "    region_df_pred = prediction_result['Predicted_df'][0][prediction_result['Predicted_df'][0][region]==1]\n",
    "    sales_real = region_df_real['NumberOfSales'].sum()\n",
    "    sales_pred= region_df_pred['NumberOfSales'].sum()\n",
    "    data_real.append(sales_real)\n",
    "    data_pred.append(sales_pred)\n",
    "\n",
    "trace_r=go.Bar(x=np.arange(0,12),\n",
    "                y=data_real,\n",
    "                name='Real sales'\n",
    "                )\n",
    "\n",
    "trace_p=go.Bar(x=np.arange(0,12),\n",
    "                 y=data_pred,\n",
    "                 name='Preicted Sales')\n",
    "\n",
    "data_tot = [trace_r, trace_p]\n",
    "layout = go.Layout(\n",
    "    barmode='group',\n",
    "    title='Real vs Predicted sales per region in March17',\n",
    "    yaxis=dict(title='Sales'),\n",
    "    xaxis=dict(title='Region')\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data_tot, layout=layout)\n",
    "iplot(fig, filename='Population info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
