{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.linear_model import Lasso,Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score,mean_absolute_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None) # no truncate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment settings\n",
    "data_path_out = 'Data/output/'\n",
    "    \n",
    "# Deserialize previously saved data from \"data-visualization\"\n",
    "with open(data_path_out + 'train_pp.obj', 'rb') as file:\n",
    "    all_train = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_orig = all_train.copy()\n",
    "all_train = all_train.drop('Region',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop now useless variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = all_train.drop(labels = ['NumberOfCustomers'],axis=1)\n",
    "all_train = all_train.drop('Date',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "    \n",
    "# model = Lasso(alpha=50)\n",
    "# model2 = Ridge(alpha=1)\n",
    "# model3 =XGBRegressor(max_depth=4,\n",
    "#                             gamma=0.05, \n",
    "#                             learning_rate=0.05, \n",
    "#                                  n_estimators=500,\n",
    "#                                  subsample=0.3, silent=1,\n",
    "#                                  random_state =7, nthread = -1)\n",
    "\n",
    "# model4 = GradientBoostingRegressor(n_estimators=500, learning_rate=0.05,\n",
    "#                                        max_depth=2,loss='lad',random_state =5)\n",
    "\n",
    "\n",
    "# model = AveragingModels(models = (model1,model2,model3,model4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation store by store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {}\n",
    "# for storeid in all_train.StoreID.unique():\n",
    "#     train = all_train[all_train.StoreID == storeid]\n",
    "#     y_train = train.NumberOfSales\n",
    "#     x_train = train.drop('NumberOfSales',axis = 1)\n",
    "#     kfold = KFold(n_splits=10,shuffle = True, random_state=7)\n",
    "#     results[storeid] = cross_val_score(model, x_train, y_train, scoring='r2', cv=kfold)\n",
    "#     print('Cross-validation for {} -> score: {:.4f} with +/- {:.4f}'\\\n",
    "#           .format(storeid,results[storeid].mean(),results[storeid].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results = pd.DataFrame.from_dict(results).T\n",
    "# df_results_mean = df_results.mean(axis=1)\n",
    "# df_results_mean[df_results_mean < 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = all_train.drop(\"Differential\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lanzi Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train by month\n",
    "def split_dataset_bymonth(test_year, test_months, train_set):\n",
    "    test_mask = (train.year == test_year) & train.month.isin(test_months)\n",
    "    \n",
    "    # define the train set\n",
    "    train_dataset = train[~test_mask]\n",
    "    x_train = train_dataset.drop('NumberOfSales', axis=1)\n",
    "    y_train = train_dataset.NumberOfSales\n",
    "    \n",
    "    # define the test set\n",
    "    test_dataset = train[test_mask]\n",
    "    x_test = test_dataset.drop('NumberOfSales', axis=1)\n",
    "    y_test = test_dataset.NumberOfSales\n",
    "    \n",
    "    return (x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store r2 1000 -> 0.8179\n",
      "store mae 1000 -> 902.23\n",
      "store r2 1001 -> 0.8272\n",
      "store mae 1001 -> 379.26\n",
      "store r2 1002 -> 0.9624\n",
      "store mae 1002 -> 327.66\n",
      "store r2 1003 -> 0.9483\n",
      "store mae 1003 -> 395.26\n",
      "store r2 1004 -> 0.9505\n",
      "store mae 1004 -> 254.66\n",
      "store r2 1005 -> 0.9138\n",
      "store mae 1005 -> 361.64\n",
      "store r2 1006 -> 0.9256\n",
      "store mae 1006 -> 546.09\n",
      "store r2 1007 -> 0.8992\n",
      "store mae 1007 -> 344.53\n",
      "store r2 1008 -> 0.8723\n",
      "store mae 1008 -> 704.88\n",
      "store r2 1009 -> 0.9440\n",
      "store mae 1009 -> 445.39\n",
      "store r2 1010 -> 0.9107\n",
      "store mae 1010 -> 512.39\n",
      "store r2 1011 -> 0.9134\n",
      "store mae 1011 -> 221.69\n",
      "store r2 1012 -> 0.9685\n",
      "store mae 1012 -> 371.39\n",
      "store r2 1013 -> 0.9717\n",
      "store mae 1013 -> 298.91\n",
      "store r2 1014 -> 0.9229\n",
      "store mae 1014 -> 330.70\n",
      "store r2 1015 -> 0.9503\n",
      "store mae 1015 -> 421.91\n",
      "store r2 1016 -> 0.8952\n",
      "store mae 1016 -> 382.10\n",
      "store r2 1017 -> 0.9559\n",
      "store mae 1017 -> 199.67\n",
      "store r2 1018 -> 0.9345\n",
      "store mae 1018 -> 294.73\n",
      "store r2 1019 -> 0.9666\n",
      "store mae 1019 -> 310.05\n",
      "store r2 1020 -> 0.9183\n",
      "store mae 1020 -> 539.58\n",
      "store r2 1021 -> 0.9684\n",
      "store mae 1021 -> 330.08\n",
      "store r2 1022 -> 0.9330\n",
      "store mae 1022 -> 481.58\n",
      "store r2 1023 -> 0.9634\n",
      "store mae 1023 -> 255.69\n",
      "store r2 1024 -> 0.9517\n",
      "store mae 1024 -> 330.73\n",
      "store r2 1025 -> 0.8600\n",
      "store mae 1025 -> 547.24\n",
      "store r2 1026 -> 0.9611\n",
      "store mae 1026 -> 304.23\n",
      "store r2 1027 -> 0.9330\n",
      "store mae 1027 -> 270.93\n",
      "store r2 1028 -> 0.8830\n",
      "store mae 1028 -> 504.92\n",
      "store r2 1029 -> 0.9577\n",
      "store mae 1029 -> 337.85\n",
      "store r2 1030 -> 0.9247\n",
      "store mae 1030 -> 470.56\n",
      "store r2 1031 -> 0.8759\n",
      "store mae 1031 -> 338.39\n",
      "store r2 1032 -> 0.9665\n",
      "store mae 1032 -> 314.34\n",
      "store r2 1033 -> 0.9799\n",
      "store mae 1033 -> 276.65\n",
      "store r2 1034 -> 0.9034\n",
      "store mae 1034 -> 333.96\n",
      "store r2 1035 -> 0.9677\n",
      "store mae 1035 -> 368.65\n",
      "store r2 1036 -> 0.9305\n",
      "store mae 1036 -> 400.05\n",
      "store r2 1037 -> 0.8973\n",
      "store mae 1037 -> 804.57\n",
      "store r2 1038 -> 0.9248\n",
      "store mae 1038 -> 594.74\n",
      "store r2 1039 -> 0.9554\n",
      "store mae 1039 -> 335.95\n",
      "store r2 1040 -> 0.9580\n",
      "store mae 1040 -> 265.24\n",
      "store r2 1041 -> 0.9492\n",
      "store mae 1041 -> 281.80\n",
      "store r2 1042 -> 0.9447\n",
      "store mae 1042 -> 292.45\n",
      "store r2 1043 -> 0.8758\n",
      "store mae 1043 -> 503.79\n",
      "store r2 1044 -> 0.9597\n",
      "store mae 1044 -> 275.22\n",
      "store r2 1045 -> 0.9444\n",
      "store mae 1045 -> 369.46\n",
      "store r2 1046 -> 0.9173\n",
      "store mae 1046 -> 516.06\n",
      "store r2 1047 -> 0.8546\n",
      "store mae 1047 -> 584.91\n",
      "store r2 1048 -> 0.9163\n",
      "store mae 1048 -> 497.65\n",
      "store r2 1049 -> 0.7919\n",
      "store mae 1049 -> 635.36\n",
      "store r2 1050 -> 0.9681\n",
      "store mae 1050 -> 372.99\n",
      "store r2 1051 -> 0.9252\n",
      "store mae 1051 -> 412.67\n",
      "store r2 1052 -> 0.9380\n",
      "store mae 1052 -> 309.20\n",
      "store r2 1053 -> 0.9260\n",
      "store mae 1053 -> 530.43\n",
      "store r2 1054 -> 0.8105\n",
      "store mae 1054 -> 414.65\n",
      "store r2 1055 -> 0.9396\n",
      "store mae 1055 -> 267.44\n",
      "store r2 1056 -> 0.9375\n",
      "store mae 1056 -> 259.42\n",
      "store r2 1057 -> 0.9450\n",
      "store mae 1057 -> 908.43\n",
      "store r2 1058 -> 0.9115\n",
      "store mae 1058 -> 287.53\n",
      "store r2 1059 -> 0.9776\n",
      "store mae 1059 -> 236.22\n",
      "store r2 1060 -> 0.9630\n",
      "store mae 1060 -> 220.38\n",
      "store r2 1061 -> 0.9690\n",
      "store mae 1061 -> 454.95\n",
      "store r2 1062 -> 0.9663\n",
      "store mae 1062 -> 264.68\n",
      "store r2 1063 -> 0.9695\n",
      "store mae 1063 -> 156.70\n",
      "store r2 1064 -> 0.9631\n",
      "store mae 1064 -> 337.23\n",
      "store r2 1065 -> 0.9179\n",
      "store mae 1065 -> 496.95\n",
      "store r2 1066 -> 0.9397\n",
      "store mae 1066 -> 535.52\n",
      "store r2 1067 -> 0.9324\n",
      "store mae 1067 -> 292.32\n",
      "store r2 1068 -> 0.7640\n",
      "store mae 1068 -> 752.80\n",
      "store r2 1069 -> 0.9130\n",
      "store mae 1069 -> 361.13\n",
      "store r2 1070 -> 0.9444\n",
      "store mae 1070 -> 462.55\n",
      "store r2 1071 -> 0.9458\n",
      "store mae 1071 -> 306.56\n",
      "store r2 1072 -> 0.9398\n",
      "store mae 1072 -> 259.28\n",
      "store r2 1073 -> 0.9513\n",
      "store mae 1073 -> 565.35\n",
      "store r2 1074 -> 0.9314\n",
      "store mae 1074 -> 345.16\n",
      "store r2 1075 -> 0.9164\n",
      "store mae 1075 -> 598.52\n",
      "store r2 1076 -> 0.9400\n",
      "store mae 1076 -> 203.24\n",
      "store r2 1077 -> 0.8363\n",
      "store mae 1077 -> 598.76\n",
      "store r2 1078 -> 0.9675\n",
      "store mae 1078 -> 226.89\n",
      "store r2 1079 -> 0.9252\n",
      "store mae 1079 -> 478.09\n",
      "store r2 1080 -> 0.8388\n",
      "store mae 1080 -> 430.29\n",
      "store r2 1081 -> 0.9533\n",
      "store mae 1081 -> 452.21\n",
      "store r2 1082 -> 0.9133\n",
      "store mae 1082 -> 384.41\n",
      "store r2 1083 -> 0.9039\n",
      "store mae 1083 -> 388.39\n",
      "store r2 1084 -> 0.9617\n",
      "store mae 1084 -> 216.24\n",
      "store r2 1085 -> 0.9572\n",
      "store mae 1085 -> 241.77\n",
      "store r2 1086 -> 0.9353\n",
      "store mae 1086 -> 442.35\n",
      "store r2 1087 -> 0.8458\n",
      "store mae 1087 -> 298.76\n",
      "store r2 1088 -> 0.9746\n",
      "store mae 1088 -> 398.52\n",
      "store r2 1089 -> 0.9405\n",
      "store mae 1089 -> 432.35\n",
      "store r2 1090 -> 0.7726\n",
      "store mae 1090 -> 607.88\n",
      "store r2 1091 -> 0.9688\n",
      "store mae 1091 -> 448.45\n",
      "store r2 1092 -> 0.9408\n",
      "store mae 1092 -> 358.37\n",
      "store r2 1093 -> 0.8957\n",
      "store mae 1093 -> 369.36\n",
      "store r2 1094 -> 0.9142\n",
      "store mae 1094 -> 467.19\n",
      "store r2 1095 -> 0.9453\n",
      "store mae 1095 -> 356.18\n",
      "store r2 1096 -> 0.9361\n",
      "store mae 1096 -> 348.77\n",
      "store r2 1097 -> 0.9402\n",
      "store mae 1097 -> 424.68\n",
      "store r2 1098 -> 0.8785\n",
      "store mae 1098 -> 230.49\n",
      "store r2 1099 -> 0.8726\n",
      "store mae 1099 -> 433.20\n",
      "store r2 1100 -> 0.9089\n",
      "store mae 1100 -> 364.17\n",
      "store r2 1101 -> 0.9143\n",
      "store mae 1101 -> 275.95\n",
      "store r2 1102 -> 0.9470\n",
      "store mae 1102 -> 437.39\n",
      "store r2 1103 -> 0.9443\n",
      "store mae 1103 -> 315.24\n",
      "store r2 1104 -> 0.9119\n",
      "store mae 1104 -> 436.15\n",
      "store r2 1105 -> 0.9385\n",
      "store mae 1105 -> 205.28\n",
      "store r2 1106 -> 0.9128\n",
      "store mae 1106 -> 550.65\n",
      "store r2 1107 -> 0.9395\n",
      "store mae 1107 -> 744.97\n",
      "store r2 1108 -> 0.7592\n",
      "store mae 1108 -> 618.47\n",
      "store r2 1109 -> 0.9234\n",
      "store mae 1109 -> 266.30\n",
      "store r2 1110 -> 0.9572\n",
      "store mae 1110 -> 405.48\n",
      "store r2 1111 -> 0.8715\n",
      "store mae 1111 -> 472.18\n",
      "store r2 1112 -> 0.9602\n",
      "store mae 1112 -> 317.83\n",
      "store r2 1113 -> 0.9141\n",
      "store mae 1113 -> 331.88\n",
      "store r2 1114 -> 0.7135\n",
      "store mae 1114 -> 969.05\n",
      "store r2 1115 -> 0.9649\n",
      "store mae 1115 -> 162.80\n",
      "store r2 1116 -> 0.9288\n",
      "store mae 1116 -> 322.97\n",
      "store r2 1117 -> 0.8857\n",
      "store mae 1117 -> 427.61\n",
      "store r2 1118 -> 0.9500\n",
      "store mae 1118 -> 466.68\n",
      "store r2 1119 -> 0.9078\n",
      "store mae 1119 -> 381.28\n",
      "store r2 1120 -> 0.9614\n",
      "store mae 1120 -> 436.69\n",
      "store r2 1121 -> 0.9180\n",
      "store mae 1121 -> 386.89\n",
      "store r2 1122 -> 0.9352\n",
      "store mae 1122 -> 285.83\n",
      "store r2 1123 -> 0.9101\n",
      "store mae 1123 -> 368.30\n",
      "store r2 1124 -> 0.9431\n",
      "store mae 1124 -> 442.89\n",
      "store r2 1125 -> 0.8878\n",
      "store mae 1125 -> 401.15\n",
      "store r2 1126 -> 0.9542\n",
      "store mae 1126 -> 247.17\n",
      "store r2 1127 -> 0.9412\n",
      "store mae 1127 -> 214.29\n",
      "store r2 1128 -> 0.9442\n",
      "store mae 1128 -> 455.20\n",
      "store r2 1129 -> 0.8207\n",
      "store mae 1129 -> 1059.29\n",
      "store r2 1130 -> 0.9116\n",
      "store mae 1130 -> 316.40\n",
      "store r2 1131 -> 0.9250\n",
      "store mae 1131 -> 494.21\n",
      "store r2 1132 -> 0.9302\n",
      "store mae 1132 -> 456.55\n",
      "store r2 1133 -> 0.9518\n",
      "store mae 1133 -> 329.87\n",
      "store r2 1134 -> 0.9170\n",
      "store mae 1134 -> 392.35\n",
      "store r2 1135 -> 0.9248\n",
      "store mae 1135 -> 330.25\n",
      "store r2 1136 -> 0.9108\n",
      "store mae 1136 -> 296.02\n",
      "store r2 1137 -> 0.8620\n",
      "store mae 1137 -> 441.12\n",
      "store r2 1138 -> 0.8489\n",
      "store mae 1138 -> 586.29\n",
      "store r2 1139 -> 0.9224\n",
      "store mae 1139 -> 484.10\n",
      "store r2 1140 -> 0.9614\n",
      "store mae 1140 -> 232.31\n",
      "store r2 1141 -> 0.9490\n",
      "store mae 1141 -> 298.54\n",
      "store r2 1142 -> 0.9510\n",
      "store mae 1142 -> 396.24\n",
      "store r2 1143 -> 0.9238\n",
      "store mae 1143 -> 291.07\n",
      "store r2 1144 -> 0.9476\n",
      "store mae 1144 -> 310.05\n",
      "store r2 1145 -> 0.9387\n",
      "store mae 1145 -> 425.94\n",
      "store r2 1146 -> 0.9388\n",
      "store mae 1146 -> 321.00\n",
      "store r2 1147 -> 0.9322\n",
      "store mae 1147 -> 546.34\n",
      "store r2 1148 -> 0.9404\n",
      "store mae 1148 -> 231.70\n",
      "store r2 1149 -> 0.9454\n",
      "store mae 1149 -> 263.35\n",
      "store r2 1150 -> 0.9284\n",
      "store mae 1150 -> 274.71\n",
      "store r2 1151 -> 0.9261\n",
      "store mae 1151 -> 283.67\n",
      "store r2 1152 -> 0.9484\n",
      "store mae 1152 -> 483.93\n",
      "store r2 1153 -> 0.9487\n",
      "store mae 1153 -> 409.25\n",
      "store r2 1154 -> 0.9253\n",
      "store mae 1154 -> 339.24\n",
      "store r2 1155 -> 0.9732\n",
      "store mae 1155 -> 303.01\n",
      "store r2 1156 -> 0.9684\n",
      "store mae 1156 -> 352.27\n",
      "store r2 1157 -> 0.9450\n",
      "store mae 1157 -> 302.02\n",
      "store r2 1158 -> 0.9531\n",
      "store mae 1158 -> 427.25\n",
      "store r2 1159 -> 0.9230\n",
      "store mae 1159 -> 436.17\n",
      "store r2 1160 -> 0.9488\n",
      "store mae 1160 -> 410.15\n",
      "store r2 1161 -> 0.8966\n",
      "store mae 1161 -> 306.40\n",
      "store r2 1162 -> 0.9077\n",
      "store mae 1162 -> 329.10\n",
      "store r2 1163 -> 0.9544\n",
      "store mae 1163 -> 203.46\n",
      "store r2 1164 -> 0.9346\n",
      "store mae 1164 -> 301.74\n",
      "store r2 1165 -> 0.8117\n",
      "store mae 1165 -> 442.43\n",
      "store r2 1166 -> 0.8882\n",
      "store mae 1166 -> 281.86\n",
      "store r2 1167 -> 0.8663\n",
      "store mae 1167 -> 344.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store r2 1168 -> 0.9410\n",
      "store mae 1168 -> 454.96\n",
      "store r2 1169 -> 0.9154\n",
      "store mae 1169 -> 502.13\n",
      "store r2 1170 -> 0.9680\n",
      "store mae 1170 -> 360.58\n",
      "store r2 1171 -> 0.8907\n",
      "store mae 1171 -> 184.33\n",
      "store r2 1172 -> 0.9276\n",
      "store mae 1172 -> 439.26\n",
      "store r2 1173 -> 0.9455\n",
      "store mae 1173 -> 305.47\n",
      "store r2 1174 -> 0.9359\n",
      "store mae 1174 -> 390.45\n",
      "store r2 1175 -> 0.9088\n",
      "store mae 1175 -> 386.69\n",
      "store r2 1176 -> 0.9631\n",
      "store mae 1176 -> 399.99\n",
      "store r2 1177 -> 0.9505\n",
      "store mae 1177 -> 403.36\n",
      "store r2 1178 -> 0.9377\n",
      "store mae 1178 -> 385.84\n",
      "store r2 1179 -> 0.9373\n",
      "store mae 1179 -> 277.51\n",
      "store r2 1180 -> 0.9703\n",
      "store mae 1180 -> 229.20\n",
      "store r2 1181 -> 0.9734\n",
      "store mae 1181 -> 357.88\n",
      "store r2 1182 -> 0.9178\n",
      "store mae 1182 -> 203.80\n",
      "store r2 1183 -> 0.8898\n",
      "store mae 1183 -> 227.66\n",
      "store r2 1184 -> 0.9378\n",
      "store mae 1184 -> 297.80\n",
      "store r2 1185 -> 0.9541\n",
      "store mae 1185 -> 364.58\n",
      "store r2 1186 -> 0.9517\n",
      "store mae 1186 -> 412.31\n",
      "store r2 1187 -> 0.8922\n",
      "store mae 1187 -> 269.96\n",
      "store r2 1188 -> 0.9517\n",
      "store mae 1188 -> 720.84\n",
      "store r2 1189 -> 0.8893\n",
      "store mae 1189 -> 578.42\n",
      "store r2 1190 -> 0.9095\n",
      "store mae 1190 -> 236.56\n",
      "store r2 1191 -> 0.9667\n",
      "store mae 1191 -> 155.51\n",
      "store r2 1192 -> 0.8598\n",
      "store mae 1192 -> 404.24\n",
      "store r2 1193 -> 0.9199\n",
      "store mae 1193 -> 323.99\n",
      "store r2 1194 -> 0.9237\n",
      "store mae 1194 -> 238.51\n",
      "store r2 1195 -> 0.9421\n",
      "store mae 1195 -> 298.11\n",
      "store r2 1196 -> 0.9046\n",
      "store mae 1196 -> 251.78\n",
      "store r2 1197 -> 0.9751\n",
      "store mae 1197 -> 244.51\n",
      "store r2 1198 -> 0.9626\n",
      "store mae 1198 -> 286.50\n",
      "store r2 1199 -> 0.9538\n",
      "store mae 1199 -> 338.84\n",
      "store r2 1200 -> 0.9010\n",
      "store mae 1200 -> 332.97\n",
      "store r2 1201 -> 0.9385\n",
      "store mae 1201 -> 323.48\n",
      "store r2 1202 -> 0.9283\n",
      "store mae 1202 -> 280.94\n",
      "store r2 1203 -> 0.8708\n",
      "store mae 1203 -> 328.41\n",
      "store r2 1204 -> 0.9318\n",
      "store mae 1204 -> 309.95\n",
      "store r2 1205 -> 0.9184\n",
      "store mae 1205 -> 432.00\n",
      "store r2 1206 -> 0.8663\n",
      "store mae 1206 -> 584.64\n",
      "store r2 1207 -> 0.9603\n",
      "store mae 1207 -> 311.16\n",
      "store r2 1208 -> 0.8681\n",
      "store mae 1208 -> 349.39\n",
      "store r2 1209 -> 0.9339\n",
      "store mae 1209 -> 353.81\n",
      "store r2 1210 -> 0.9594\n",
      "store mae 1210 -> 257.18\n",
      "store r2 1211 -> 0.8852\n",
      "store mae 1211 -> 358.05\n",
      "store r2 1212 -> 0.9639\n",
      "store mae 1212 -> 600.51\n",
      "store r2 1213 -> 0.9551\n",
      "store mae 1213 -> 376.11\n",
      "store r2 1214 -> 0.7835\n",
      "store mae 1214 -> 389.99\n",
      "store r2 1215 -> 0.9587\n",
      "store mae 1215 -> 337.52\n",
      "store r2 1216 -> 0.9139\n",
      "store mae 1216 -> 463.72\n",
      "store r2 1217 -> 0.9228\n",
      "store mae 1217 -> 393.44\n",
      "store r2 1218 -> 0.9349\n",
      "store mae 1218 -> 314.70\n",
      "store r2 1219 -> 0.9224\n",
      "store mae 1219 -> 288.31\n",
      "store r2 1220 -> 0.9459\n",
      "store mae 1220 -> 209.35\n",
      "store r2 1221 -> 0.9535\n",
      "store mae 1221 -> 307.45\n",
      "store r2 1222 -> 0.9410\n",
      "store mae 1222 -> 321.24\n",
      "store r2 1223 -> 0.9382\n",
      "store mae 1223 -> 484.38\n",
      "store r2 1224 -> 0.9458\n",
      "store mae 1224 -> 428.59\n",
      "store r2 1225 -> 0.9592\n",
      "store mae 1225 -> 514.54\n",
      "store r2 1226 -> 0.9262\n",
      "store mae 1226 -> 343.39\n",
      "store r2 1227 -> 0.9247\n",
      "store mae 1227 -> 241.24\n",
      "store r2 1228 -> 0.9582\n",
      "store mae 1228 -> 314.17\n",
      "store r2 1229 -> 0.9526\n",
      "store mae 1229 -> 356.50\n",
      "store r2 1230 -> 0.9108\n",
      "store mae 1230 -> 221.92\n",
      "store r2 1231 -> 0.9418\n",
      "store mae 1231 -> 358.27\n",
      "store r2 1232 -> 0.9169\n",
      "store mae 1232 -> 434.85\n",
      "store r2 1233 -> 0.9202\n",
      "store mae 1233 -> 301.99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-3d1dbcae08f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# train the model with the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# scoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-198-4da21b2b5b8f>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Train cloned base models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 327\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "\n",
    "\n",
    "scores = {}\n",
    "scores_mae= {}\n",
    "predictions = defaultdict(dict)\n",
    "store_pred = {}\n",
    "shopping_center_ids = [1129,1267,1280,1307,1330,1339,1357,1387,1676]\n",
    "region2_stores = all_train[all_train['Region_2'] ==1]['StoreID'].unique()\n",
    "ids = all_train.StoreID.unique()\n",
    "\n",
    "for storeid in ids:\n",
    "    \n",
    "    model1= Lasso(alpha=20)\n",
    "    model2 =XGBRegressor(n_estimators=100)\n",
    "    model3 = GradientBoostingRegressor(n_estimators=50, max_depth=5,learning_rate=0.07,\n",
    "                                      loss='huber',random_state =5)\n",
    "    \n",
    "    model4 = ExtraTreesRegressor(n_estimators=50)\n",
    "\n",
    "    \n",
    "    model = AveragingModels(models = (model1,model2,model3,model4)) \n",
    "\n",
    "    # split the dataset\n",
    "    train = all_train[all_train.StoreID == storeid]\n",
    "    \n",
    "    x_train, y_train, x_test, y_test =\\\n",
    "    split_dataset_bymonth(2017,[3,4], train)\n",
    "    \n",
    "    # train the model with the training set\n",
    "    model.fit(x_train, y_train)\n",
    "              \n",
    "    # scoring\n",
    "    scores[storeid] = r2_score(y_test, model.predict(x_test))\n",
    "    scores_mae[storeid]= mean_absolute_error(y_test, model.predict(x_test))\n",
    "    \n",
    "    print('store r2 {} -> {:.4f}'.format(storeid, scores[storeid]))\n",
    "    print('store mae {} -> {:.2f}'.format(storeid, scores_mae[storeid]))\n",
    "    \n",
    "    store_pred[storeid] = scores[storeid]\n",
    "    # predict the test set with the trained model\n",
    "    for month in x_test.month.unique():\n",
    "        # get daily predictions for each month in the test set\n",
    "        month_prediction =model.predict(x_test[x_test.month == month]).astype(\"int\")\n",
    "        month_actual = y_test.loc[x_test[x_test.month == month].index].values\n",
    "        \n",
    "#         if scores[storeid] <0.6 :\n",
    "#             ts_pred = pd.Series(month_prediction, index=x_test[x_test.month==month]['day_of_month']).\\\n",
    "#                 plot(figsize=(20,5), title='Region 2', marker='o')\n",
    "#             ts_act = pd.Series(month_actual, index=x_test[x_test.month==month]['day_of_month']).\\\n",
    "#                 plot(figsize=(20,5), title='Region 2', marker='x')\n",
    "#             plt.show()\n",
    "        \n",
    "        # store the monthly mean of the test set\n",
    "        predictions[storeid][month] = {\n",
    "            'predicted': np.sum(month_prediction),\n",
    "            'actual': np.sum(month_actual)        \n",
    "        }\n",
    "        predictions[storeid]['r2']=scores[storeid]\n",
    "        predictions[storeid]['mae']=scores_mae[storeid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Lanzi error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of regions\n",
    "R = sorted(all_train_orig.Region.unique().astype(int))\n",
    "# set of predicted months\n",
    "months = [key for key, value in predictions[1000].items()]\n",
    "# set of stores by region\n",
    "dict_store_byRegion = all_train_orig[['Region', 'StoreID']].drop_duplicates()\\\n",
    ".set_index('StoreID').groupby('Region').groups\n",
    "\n",
    "def region_error(region, predictions):    \n",
    "    num = 0\n",
    "    den = 0\n",
    "    for store in dict_store_byRegion[str(region)]:\n",
    "        for month in months:\n",
    "            predicted = predictions[store][month]['predicted']\n",
    "            actual = predictions[store][month]['actual']\n",
    "            \n",
    "            num += abs(actual - predicted)\n",
    "            den += actual\n",
    "    \n",
    "    return num/den\n",
    "    \n",
    "# total_error input:\n",
    "#\n",
    "# region_errors = [0.3, 0.5, ... ]\n",
    "\n",
    "def total_error(region_errors):\n",
    "#     print(region_errors)\n",
    "    return sum(region_errors)/len(region_errors)\n",
    "\n",
    "def lanzi_error(predictions):\n",
    "    region_errors = []\n",
    "    for r in R:\n",
    "        region_errors.append(region_error(r, predictions))\n",
    "    \n",
    "    return total_error(region_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lanzi error: {}'.format(lanzi_error(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
