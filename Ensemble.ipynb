{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.linear_model import Lasso,Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score,mean_absolute_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None) # no truncate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StoreID', 'Date', 'IsHoliday', 'IsOpen', 'HasPromotions',\n",
       "       'NearestCompetitor', 'Region_AreaKM2', 'Region_GDP',\n",
       "       'Region_PopulationK', 'CloudCover', 'Max_Dew_PointC', 'Max_Humidity',\n",
       "       'Max_Sea_Level_PressurehPa', 'Max_TemperatureC', 'Max_VisibilityKm',\n",
       "       'Max_Wind_SpeedKm_h', 'Mean_Dew_PointC', 'Mean_Humidity',\n",
       "       'Mean_Sea_Level_PressurehPa', 'Mean_TemperatureC', 'Mean_VisibilityKm',\n",
       "       'Mean_Wind_SpeedKm_h', 'Min_Dew_PointC', 'Min_Humidity',\n",
       "       'Min_Sea_Level_PressurehPa', 'Min_TemperatureC', 'Min_VisibilitykM',\n",
       "       'Precipitationmm', 'WindDirDegrees', 'Events_Hail', 'Hol_and_open',\n",
       "       'Region_PD', 'week_of_month', 'year', 'quarter', 'month',\n",
       "       'day_of_month', 'day_of_week', 'day_of_year', 'WeekOfYear',\n",
       "       'days_in_month', 'Region_0', 'Region_1', 'Region_10', 'Region_2',\n",
       "       'Region_3', 'Region_4', 'Region_5', 'Region_7', 'Region_9', 'Region_6',\n",
       "       'Region_8', 'AssortmentType_General',\n",
       "       'AssortmentType_With Non-Food Department',\n",
       "       'AssortmentType_With Fish Department', 'StoreType_Hyper Market',\n",
       "       'StoreType_Standard Market', 'StoreType_Super Market',\n",
       "       'StoreType_Shopping Center', 'Events_Fog', 'Events_Rain', 'Events_Snow',\n",
       "       'Events_Thunderstorm', 'Events_Normal', 'Region', 'HolidaysWeekBefore',\n",
       "       'HolidaysWeekCurrent', 'HolidaysWeekAfter', 'PromoWeekBefore',\n",
       "       'PromoWeekCurrent', 'PromoWeekAfter', 'NumberOfSales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Environment settings\n",
    "data_path_out = 'Data/output/'\n",
    "    \n",
    "# Deserialize previously saved data from \"data-visualization\"\n",
    "with open(data_path_out + 'train_pp.obj', 'rb') as file:\n",
    "    all_train = pickle.load(file)\n",
    "all_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_orig = all_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop now useless variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = all_train.drop(labels = ['Region'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dates = pd.DatetimeIndex(all_train['Date'])\n",
    "month_dict = { d.strftime(\"%B%Y\") :datetime.strptime(d.strftime('%m-%Y'),'%m-%Y') for d in all_dates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_training(training_interval=['03-2017','02-2018'],\n",
    "                     verbose=False,\n",
    "                     regressor=RandomForestRegressor(n_estimators=50,n_jobs=-1)):\n",
    "    \n",
    "    init_date=datetime.strptime(training_interval[0],'%m-%Y')\n",
    "    end_date =datetime.strptime(training_interval[1],'%m-%Y')\n",
    "    \n",
    "    month_scores = []\n",
    "    y_test_list = []\n",
    "    predicted_list= []\n",
    "    predicted_df_list = []\n",
    "    training_months = []\n",
    "    training_df_list = []\n",
    "    \n",
    "    for month_name, date in month_dict.items():\n",
    "\n",
    "        if (date >= init_date) & (date<= end_date) :\n",
    "                if verbose== True:\n",
    "                    print(\"Doing month\",month_name)\n",
    "                    \n",
    "                #just numerical month names\n",
    "                training_months.append(month_name)\n",
    "                \n",
    "                #TEST TRAIN GENERATION\n",
    "                #--------------------\n",
    "                mask = ((all_train['month']==date.month) & (all_train['year']==date.year))\n",
    "                test = all_train[mask]\n",
    "                train = all_train[~mask]\n",
    "                \n",
    "                \n",
    "                columns_to_drop=['Date','CloudCover', 'Max_Dew_PointC', 'Max_Humidity',\n",
    "                                 'Max_Sea_Level_PressurehPa', 'Max_TemperatureC', 'Max_VisibilityKm',\n",
    "                                 'Max_Wind_SpeedKm_h', 'Mean_Dew_PointC', 'Mean_Humidity',\n",
    "                                 'Mean_Sea_Level_PressurehPa', 'Mean_TemperatureC', 'Mean_VisibilityKm',\n",
    "                                 'Mean_Wind_SpeedKm_h', 'Min_Dew_PointC', 'Min_Humidity',\n",
    "                                 'Min_Sea_Level_PressurehPa', 'Min_TemperatureC', 'Min_VisibilitykM',\n",
    "                                 'Precipitationmm', 'WindDirDegrees']\n",
    "                \n",
    "\n",
    "        \n",
    "                train = train.drop(columns_to_drop,axis=1)\n",
    "                test = test.drop(columns_to_drop,axis=1)\n",
    "                \n",
    "                \n",
    "                y_train = train.NumberOfSales\n",
    "                X_train = train.drop('NumberOfSales',axis = 1)\n",
    "\n",
    "                y_test = test.NumberOfSales\n",
    "                X_test = test.drop('NumberOfSales',axis = 1)\n",
    "                #-------------------------------\n",
    "\n",
    "                \n",
    "                #SCALING\n",
    "                #--------------------------------\n",
    "                columns_to_scale = ['NearestCompetitor', \n",
    "                                    'Region_AreaKM2',\n",
    "                                    'Region_GDP',\n",
    "                                    'Region_PopulationK',\n",
    "                                    'Region_PD']\n",
    "    \n",
    "                scaler = RobustScaler()\n",
    "                X_train[columns_to_scale]=scaler.fit_transform(X_train[columns_to_scale])\n",
    "                X_test[columns_to_scale]=scaler.transform(X_test[columns_to_scale])\n",
    "                reg =  regressor.fit(X_train,y_train)\n",
    "                #--------------------------------\n",
    "\n",
    "                \n",
    "                #FEATURE IMPORTANCE\n",
    "               #--------------------\n",
    "                feat_labels = train.columns[0:]\n",
    "                importances = reg.feature_importances_\n",
    "                indices = np.argsort(importances)[::-1]\n",
    "                for f in range(0,10):\n",
    "                    print(\"%2d %-*s %f\" %(f+1,30,feat_labels[indices[f]],importances[indices[f]]))\n",
    "               #--------------------\n",
    "\n",
    "\n",
    "                \n",
    "                #FITTING AND SCORING\n",
    "                #--------------------\n",
    "                current_score = reg.score(X_test,y_test)\n",
    "                current_prediction = reg.predict(X_test)\n",
    "                \n",
    "                month_scores.append(current_score)\n",
    "                predicted_list.append(current_prediction)\n",
    "                y_test_list.append(y_test)\n",
    "                #--------------------\n",
    "\n",
    "                \n",
    "                if verbose == True:\n",
    "                    print(\"-Month {} has shape {}\\n\\t\".format(month_name,test.shape))\n",
    "                    print(\"-Score {:.3f}\".format(current_score))\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                # SAVE DATA FOR PLOTTING/PRINTING\n",
    "                #--------------------\n",
    "                real_df = all_train.copy()\n",
    "                month_test_df = all_train[mask]\n",
    "                month_all_train= all_train[~mask]\n",
    "\n",
    "                month_test_df= month_test_df.drop('NumberOfSales',axis=1)\n",
    "                prediction_=pd.Series(current_prediction)\n",
    "                month_test_df['NumberOfSales']=prediction_.values.astype(int)\n",
    "                predicted_df = pd.concat([month_test_df,month_all_train]).reset_index()\n",
    "                predicted_df= predicted_df[list(all_train.columns.values)]\n",
    "                \n",
    "                predicted_df_list.append(predicted_df)\n",
    "                training_df_list.append(train)\n",
    "                #--------------------\n",
    "\n",
    "                \n",
    "    return {\n",
    "        'Scores' : month_scores,\n",
    "        'Real' : y_test_list,\n",
    "        'Predictions' : predicted_list,\n",
    "        'Training_dates': training_months,\n",
    "        'Training_df' : training_df_list,\n",
    "        'Predicted_df' : predicted_df_list\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg = RandomForestRegressor(n_estimators=500,n_jobs=-1,verbose=True)\n",
    "\n",
    "model = ExtraTreesRegressor(n_estimators=50,n_jobs=-1,verbose=2)\n",
    "\n",
    "prediction_result = monthly_training(verbose=True,\n",
    "                                     training_interval=['12-2017','01-2018'],\n",
    "                                     regressor = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = all_train.drop('Date',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 1.8min\n",
      "[CV] ................................................. , total= 1.8min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 1.8min\n",
      "[CV] ................................................. , total= 1.8min\n",
      "[CV] ................................................. , total=  45.4s\n",
      "The 10 -fold crossvalidation R2 of XT is 0.92924 +/- 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.6min finished\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop=['CloudCover', 'Max_Dew_PointC', 'Max_Humidity',\n",
    "                                 'Max_Sea_Level_PressurehPa', 'Max_TemperatureC', 'Max_VisibilityKm',\n",
    "                                 'Max_Wind_SpeedKm_h', 'Mean_Dew_PointC', 'Mean_Humidity',\n",
    "                                 'Mean_Sea_Level_PressurehPa', 'Mean_TemperatureC', 'Mean_VisibilityKm',\n",
    "                                 'Mean_Wind_SpeedKm_h', 'Min_Dew_PointC', 'Min_Humidity',\n",
    "                                 'Min_Sea_Level_PressurehPa', 'Min_TemperatureC', 'Min_VisibilitykM',\n",
    "                                 'Precipitationmm','WindDirDegrees']\n",
    "\n",
    "X = all_train.drop('NumberOfSales',axis=1)\n",
    "y = all_train.NumberOfSales\n",
    "X = X.drop(columns_to_drop,axis=1)\n",
    "#SCALING\n",
    "#--------------------------------\n",
    "columns_to_scale = ['NearestCompetitor',\n",
    "                    'Region_AreaKM2',\n",
    "                    'Region_GDP',\n",
    "                    'Region_PopulationK',\n",
    "                    'Region_PD']\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X[columns_to_scale]=scaler.fit_transform(X[columns_to_scale])\n",
    "\n",
    "model = ExtraTreesRegressor()\n",
    "\n",
    "kf = KFold(5, shuffle=True, random_state=42)\n",
    "r2_cv_xt= cross_val_score(model, X, y, scoring=\"r2\", cv = kf,verbose=2,n_jobs=-1)\n",
    "\n",
    "\n",
    "print(\"The 10 -fold crossvalidation R2 of XT is {:.5f} +/- {:.3f}\".format(r2_cv_xt.mean(),r2_cv_xt.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results = pd.DataFrame.from_dict(results).T\n",
    "# df_results_mean = df_results.mean(axis=1)\n",
    "# df_results_mean[df_results_mean < 0.8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lanzi Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train by month\n",
    "def split_dataset_bymonth(test_year, test_months, train_set):\n",
    "    test_mask = (train.year == test_year) & train.month.isin(test_months)\n",
    "    \n",
    "    # define the train set\n",
    "    train_dataset = train[~test_mask]\n",
    "    x_train = train_dataset.drop('NumberOfSales', axis=1)\n",
    "    y_train = train_dataset.NumberOfSales\n",
    "    \n",
    "    # define the test set\n",
    "    test_dataset = train[test_mask]\n",
    "    x_test = test_dataset.drop('NumberOfSales', axis=1)\n",
    "    y_test = test_dataset.NumberOfSales\n",
    "    \n",
    "    return (x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store r2 1000 -> 0.8211\n",
      "store r2 1001 -> 0.8331\n",
      "store r2 1002 -> 0.9616\n",
      "store r2 1003 -> 0.9474\n",
      "store r2 1004 -> 0.9498\n",
      "store r2 1005 -> 0.9133\n",
      "store r2 1006 -> 0.9270\n",
      "store r2 1007 -> 0.9018\n",
      "store r2 1008 -> 0.8683\n",
      "store r2 1009 -> 0.9427\n",
      "store r2 1010 -> 0.9122\n",
      "store r2 1011 -> 0.9127\n",
      "store r2 1012 -> 0.9684\n",
      "store r2 1013 -> 0.9722\n",
      "store r2 1014 -> 0.9230\n",
      "store r2 1015 -> 0.9522\n",
      "store r2 1016 -> 0.8988\n",
      "store r2 1017 -> 0.9561\n",
      "store r2 1018 -> 0.9344\n",
      "store r2 1019 -> 0.9670\n",
      "store r2 1020 -> 0.9141\n",
      "store r2 1021 -> 0.9675\n",
      "store r2 1022 -> 0.9336\n",
      "store r2 1023 -> 0.9644\n",
      "store r2 1024 -> 0.9530\n",
      "store r2 1025 -> 0.8560\n",
      "store r2 1026 -> 0.9619\n",
      "store r2 1027 -> 0.9334\n",
      "store r2 1028 -> 0.8847\n",
      "store r2 1029 -> 0.9567\n",
      "store r2 1030 -> 0.9258\n",
      "store r2 1031 -> 0.8751\n",
      "store r2 1032 -> 0.9667\n",
      "store r2 1033 -> 0.9801\n",
      "store r2 1034 -> 0.9035\n",
      "store r2 1035 -> 0.9670\n",
      "store r2 1036 -> 0.9329\n",
      "store r2 1037 -> 0.8986\n",
      "store r2 1038 -> 0.9249\n",
      "store r2 1039 -> 0.9566\n",
      "store r2 1040 -> 0.9575\n",
      "store r2 1041 -> 0.9493\n",
      "store r2 1042 -> 0.9448\n",
      "store r2 1043 -> 0.8839\n",
      "store r2 1044 -> 0.9595\n",
      "store r2 1045 -> 0.9444\n",
      "store r2 1046 -> 0.9188\n",
      "store r2 1047 -> 0.8518\n",
      "store r2 1048 -> 0.9215\n",
      "store r2 1049 -> 0.7912\n",
      "store r2 1050 -> 0.9660\n",
      "store r2 1051 -> 0.9231\n",
      "store r2 1052 -> 0.9370\n",
      "store r2 1053 -> 0.9258\n",
      "store r2 1054 -> 0.8118\n",
      "store r2 1055 -> 0.9385\n",
      "store r2 1056 -> 0.9350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yannickgiovanakis/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store r2 1057 -> 0.9450\n",
      "store r2 1058 -> 0.9089\n",
      "store r2 1059 -> 0.9782\n",
      "store r2 1060 -> 0.9637\n",
      "store r2 1061 -> 0.9687\n",
      "store r2 1062 -> 0.9655\n",
      "store r2 1063 -> 0.9702\n",
      "store r2 1064 -> 0.9631\n",
      "store r2 1065 -> 0.9210\n",
      "store r2 1066 -> 0.9404\n",
      "store r2 1067 -> 0.9331\n",
      "store r2 1068 -> 0.7672\n",
      "store r2 1069 -> 0.9126\n",
      "store r2 1070 -> 0.9417\n",
      "store r2 1071 -> 0.9479\n",
      "store r2 1072 -> 0.9404\n",
      "store r2 1073 -> 0.9532\n",
      "store r2 1074 -> 0.9299\n",
      "store r2 1075 -> 0.9214\n",
      "store r2 1076 -> 0.9398\n",
      "store r2 1077 -> 0.8410\n",
      "store r2 1078 -> 0.9672\n",
      "store r2 1079 -> 0.9284\n",
      "store r2 1080 -> 0.8374\n",
      "store r2 1081 -> 0.9539\n",
      "store r2 1082 -> 0.9160\n",
      "store r2 1083 -> 0.9049\n",
      "store r2 1084 -> 0.9624\n",
      "store r2 1085 -> 0.9578\n",
      "store r2 1086 -> 0.9349\n",
      "store r2 1087 -> 0.8467\n",
      "store r2 1088 -> 0.9746\n",
      "store r2 1089 -> 0.9403\n",
      "store r2 1090 -> 0.7720\n",
      "store r2 1091 -> 0.9688\n",
      "store r2 1092 -> 0.9396\n",
      "store r2 1093 -> 0.8917\n",
      "store r2 1094 -> 0.9173\n",
      "store r2 1095 -> 0.9474\n",
      "store r2 1096 -> 0.9307\n",
      "store r2 1097 -> 0.9432\n",
      "store r2 1098 -> 0.8790\n",
      "store r2 1099 -> 0.8733\n",
      "store r2 1100 -> 0.9226\n",
      "store r2 1101 -> 0.9143\n",
      "store r2 1102 -> 0.9463\n",
      "store r2 1103 -> 0.9452\n",
      "store r2 1104 -> 0.9079\n",
      "store r2 1105 -> 0.9390\n",
      "store r2 1106 -> 0.9124\n",
      "store r2 1107 -> 0.9392\n",
      "store r2 1108 -> 0.7635\n",
      "store r2 1109 -> 0.9233\n",
      "store r2 1110 -> 0.9576\n",
      "store r2 1111 -> 0.8737\n",
      "store r2 1112 -> 0.9594\n",
      "store r2 1113 -> 0.9112\n",
      "store r2 1114 -> 0.7132\n",
      "store r2 1115 -> 0.9645\n",
      "store r2 1116 -> 0.9309\n",
      "store r2 1117 -> 0.8856\n",
      "store r2 1118 -> 0.9521\n",
      "store r2 1119 -> 0.9080\n",
      "store r2 1120 -> 0.9609\n",
      "store r2 1121 -> 0.9211\n",
      "store r2 1122 -> 0.9333\n",
      "store r2 1123 -> 0.9100\n",
      "store r2 1124 -> 0.9407\n",
      "store r2 1125 -> 0.8866\n",
      "store r2 1126 -> 0.9537\n",
      "store r2 1127 -> 0.9424\n",
      "store r2 1128 -> 0.9473\n",
      "store r2 1129 -> 0.8145\n",
      "store r2 1130 -> 0.9114\n",
      "store r2 1131 -> 0.9285\n",
      "store r2 1132 -> 0.9315\n",
      "store r2 1133 -> 0.9516\n",
      "store r2 1134 -> 0.9162\n",
      "store r2 1135 -> 0.9262\n",
      "store r2 1136 -> 0.9146\n",
      "store r2 1137 -> 0.8653\n",
      "store r2 1138 -> 0.8503\n",
      "store r2 1139 -> 0.9226\n",
      "store r2 1140 -> 0.9619\n",
      "store r2 1141 -> 0.9481\n",
      "store r2 1142 -> 0.9485\n",
      "store r2 1143 -> 0.9243\n",
      "store r2 1144 -> 0.9463\n",
      "store r2 1145 -> 0.9350\n",
      "store r2 1146 -> 0.9396\n",
      "store r2 1147 -> 0.9328\n",
      "store r2 1148 -> 0.9369\n",
      "store r2 1149 -> 0.9464\n",
      "store r2 1150 -> 0.9306\n",
      "store r2 1151 -> 0.9256\n",
      "store r2 1152 -> 0.9458\n",
      "store r2 1153 -> 0.9504\n",
      "store r2 1154 -> 0.9294\n",
      "store r2 1155 -> 0.9731\n",
      "store r2 1156 -> 0.9690\n",
      "store r2 1157 -> 0.9458\n",
      "store r2 1158 -> 0.9539\n",
      "store r2 1159 -> 0.9247\n",
      "store r2 1160 -> 0.9516\n",
      "store r2 1161 -> 0.8997\n",
      "store r2 1162 -> 0.9079\n",
      "store r2 1163 -> 0.9545\n",
      "store r2 1164 -> 0.9359\n",
      "store r2 1165 -> 0.8157\n",
      "store r2 1166 -> 0.8877\n",
      "store r2 1167 -> 0.8665\n",
      "store r2 1168 -> 0.9401\n",
      "store r2 1169 -> 0.9152\n",
      "store r2 1170 -> 0.9676\n",
      "store r2 1171 -> 0.8909\n",
      "store r2 1172 -> 0.9276\n",
      "store r2 1173 -> 0.9465\n",
      "store r2 1174 -> 0.9358\n",
      "store r2 1175 -> 0.9072\n",
      "store r2 1176 -> 0.9638\n",
      "store r2 1177 -> 0.9504\n",
      "store r2 1178 -> 0.9361\n",
      "store r2 1179 -> 0.9387\n",
      "store r2 1180 -> 0.9700\n",
      "store r2 1181 -> 0.9733\n",
      "store r2 1182 -> 0.9199\n",
      "store r2 1183 -> 0.8903\n",
      "store r2 1184 -> 0.9370\n",
      "store r2 1185 -> 0.9543\n",
      "store r2 1186 -> 0.9524\n",
      "store r2 1187 -> 0.8920\n",
      "store r2 1188 -> 0.9526\n",
      "store r2 1189 -> 0.8905\n",
      "store r2 1190 -> 0.9094\n",
      "store r2 1191 -> 0.9676\n",
      "store r2 1192 -> 0.8603\n",
      "store r2 1193 -> 0.9190\n",
      "store r2 1194 -> 0.9142\n",
      "store r2 1195 -> 0.9402\n",
      "store r2 1196 -> 0.9050\n",
      "store r2 1197 -> 0.9741\n",
      "store r2 1198 -> 0.9621\n",
      "store r2 1199 -> 0.9538\n",
      "store r2 1200 -> 0.9009\n",
      "store r2 1201 -> 0.9339\n",
      "store r2 1202 -> 0.9317\n",
      "store r2 1203 -> 0.8720\n",
      "store r2 1204 -> 0.9319\n",
      "store r2 1205 -> 0.9187\n",
      "store r2 1206 -> 0.8720\n",
      "store r2 1207 -> 0.9603\n",
      "store r2 1208 -> 0.8672\n",
      "store r2 1209 -> 0.9336\n",
      "store r2 1210 -> 0.9613\n",
      "store r2 1211 -> 0.8850\n",
      "store r2 1212 -> 0.9636\n",
      "store r2 1213 -> 0.9554\n",
      "store r2 1214 -> 0.7708\n",
      "store r2 1215 -> 0.9584\n",
      "store r2 1216 -> 0.9125\n",
      "store r2 1217 -> 0.9223\n",
      "store r2 1218 -> 0.9333\n",
      "store r2 1219 -> 0.9224\n",
      "store r2 1220 -> 0.9477\n",
      "store r2 1221 -> 0.9554\n",
      "store r2 1222 -> 0.9417\n",
      "store r2 1223 -> 0.9395\n",
      "store r2 1224 -> 0.9462\n",
      "store r2 1225 -> 0.9604\n",
      "store r2 1226 -> 0.9309\n",
      "store r2 1227 -> 0.9251\n",
      "store r2 1228 -> 0.9576\n",
      "store r2 1229 -> 0.9532\n",
      "store r2 1230 -> 0.9085\n",
      "store r2 1231 -> 0.9397\n",
      "store r2 1232 -> 0.9175\n",
      "store r2 1233 -> 0.9223\n",
      "store r2 1234 -> 0.9550\n",
      "store r2 1235 -> 0.9806\n",
      "store r2 1236 -> 0.9154\n",
      "store r2 1237 -> 0.9264\n",
      "store r2 1238 -> 0.9709\n",
      "store r2 1239 -> 0.8970\n",
      "store r2 1240 -> 0.9598\n",
      "store r2 1241 -> 0.9663\n",
      "store r2 1242 -> 0.9006\n",
      "store r2 1243 -> 0.9582\n",
      "store r2 1244 -> 0.9604\n",
      "store r2 1245 -> 0.9575\n",
      "store r2 1246 -> 0.8463\n",
      "store r2 1247 -> 0.9314\n",
      "store r2 1248 -> 0.9191\n",
      "store r2 1249 -> 0.9539\n",
      "store r2 1250 -> 0.9616\n",
      "store r2 1251 -> 0.9544\n",
      "store r2 1252 -> 0.9529\n",
      "store r2 1253 -> 0.9650\n",
      "store r2 1254 -> 0.9433\n",
      "store r2 1255 -> 0.9630\n",
      "store r2 1256 -> 0.9465\n",
      "store r2 1257 -> 0.9289\n",
      "store r2 1258 -> 0.9618\n",
      "store r2 1259 -> 0.8776\n",
      "store r2 1260 -> 0.9382\n",
      "store r2 1261 -> 0.9097\n",
      "store r2 1262 -> 0.9131\n",
      "store r2 1263 -> 0.9692\n",
      "store r2 1264 -> 0.9049\n",
      "store r2 1265 -> 0.9306\n",
      "store r2 1266 -> 0.9290\n",
      "store r2 1267 -> 0.8191\n",
      "store r2 1268 -> 0.9437\n",
      "store r2 1269 -> 0.9072\n",
      "store r2 1270 -> 0.9229\n",
      "store r2 1271 -> 0.8316\n",
      "store r2 1272 -> 0.9787\n",
      "store r2 1273 -> 0.9450\n",
      "store r2 1274 -> 0.9453\n",
      "store r2 1275 -> 0.9589\n",
      "store r2 1276 -> 0.9481\n",
      "store r2 1277 -> 0.9033\n",
      "store r2 1278 -> 0.9558\n",
      "store r2 1279 -> 0.8689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yannickgiovanakis/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store r2 1280 -> 0.8579\n",
      "store r2 1281 -> 0.9031\n",
      "store r2 1282 -> 0.9240\n",
      "store r2 1283 -> 0.9323\n",
      "store r2 1284 -> 0.9122\n",
      "store r2 1285 -> 0.8957\n",
      "store r2 1286 -> 0.9694\n",
      "store r2 1287 -> 0.9542\n",
      "store r2 1288 -> 0.9388\n",
      "store r2 1289 -> 0.9192\n",
      "store r2 1290 -> 0.8918\n",
      "store r2 1291 -> 0.8706\n",
      "store r2 1292 -> 0.9292\n",
      "store r2 1293 -> 0.9266\n",
      "store r2 1294 -> 0.8610\n",
      "store r2 1295 -> 0.9150\n",
      "store r2 1296 -> 0.8968\n",
      "store r2 1297 -> 0.9654\n",
      "store r2 1298 -> 0.9468\n",
      "store r2 1299 -> 0.9189\n",
      "store r2 1300 -> 0.9661\n",
      "store r2 1301 -> 0.9247\n",
      "store r2 1302 -> 0.9623\n",
      "store r2 1303 -> 0.8353\n",
      "store r2 1304 -> 0.9589\n",
      "store r2 1305 -> 0.8745\n",
      "store r2 1306 -> 0.8833\n",
      "store r2 1307 -> 0.6442\n",
      "store r2 1308 -> 0.9765\n",
      "store r2 1309 -> 0.9337\n",
      "store r2 1310 -> 0.8469\n",
      "store r2 1311 -> 0.9101\n",
      "store r2 1312 -> 0.8655\n",
      "store r2 1313 -> 0.9521\n",
      "store r2 1314 -> 0.9295\n",
      "store r2 1315 -> 0.8734\n",
      "store r2 1316 -> 0.9553\n",
      "store r2 1317 -> 0.9261\n",
      "store r2 1318 -> 0.9322\n",
      "store r2 1319 -> 0.9258\n",
      "store r2 1320 -> 0.9786\n",
      "store r2 1321 -> 0.9551\n",
      "store r2 1322 -> 0.9362\n",
      "store r2 1323 -> 0.9349\n",
      "store r2 1324 -> 0.9024\n",
      "store r2 1325 -> 0.9701\n",
      "store r2 1326 -> 0.8817\n",
      "store r2 1327 -> 0.9576\n",
      "store r2 1328 -> 0.9414\n",
      "store r2 1329 -> 0.9381\n",
      "store r2 1330 -> 0.3753\n",
      "store r2 1331 -> 0.9636\n",
      "store r2 1332 -> 0.8249\n",
      "store r2 1333 -> 0.9573\n",
      "store r2 1334 -> 0.9031\n",
      "store r2 1335 -> 0.9318\n",
      "store r2 1336 -> 0.6510\n",
      "store r2 1337 -> 0.9265\n",
      "store r2 1338 -> 0.9126\n",
      "store r2 1339 -> 0.7038\n",
      "store r2 1340 -> 0.9541\n",
      "store r2 1341 -> 0.9255\n",
      "store r2 1342 -> 0.9521\n",
      "store r2 1343 -> 0.9524\n",
      "store r2 1344 -> 0.9201\n",
      "store r2 1345 -> 0.9141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yannickgiovanakis/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store r2 1346 -> 0.8705\n",
      "store r2 1347 -> 0.9492\n",
      "store r2 1348 -> 0.9105\n",
      "store r2 1349 -> 0.8342\n",
      "store r2 1350 -> 0.9555\n",
      "store r2 1351 -> 0.8845\n",
      "store r2 1352 -> 0.7956\n",
      "store r2 1353 -> 0.9487\n",
      "store r2 1354 -> 0.9391\n",
      "store r2 1355 -> 0.9755\n",
      "store r2 1356 -> 0.9309\n",
      "store r2 1357 -> 0.8356\n",
      "store r2 1358 -> 0.9701\n",
      "store r2 1359 -> 0.8912\n",
      "store r2 1360 -> 0.9296\n",
      "store r2 1361 -> 0.9740\n",
      "store r2 1362 -> 0.9350\n",
      "store r2 1363 -> 0.9618\n",
      "store r2 1364 -> 0.8571\n",
      "store r2 1365 -> 0.9653\n",
      "store r2 1366 -> 0.9543\n",
      "store r2 1367 -> 0.7979\n",
      "store r2 1368 -> 0.9249\n",
      "store r2 1369 -> 0.9360\n",
      "store r2 1370 -> 0.8124\n",
      "store r2 1371 -> 0.9647\n",
      "store r2 1372 -> 0.9478\n",
      "store r2 1373 -> 0.9289\n",
      "store r2 1374 -> 0.9087\n",
      "store r2 1375 -> 0.9447\n",
      "store r2 1376 -> 0.9640\n",
      "store r2 1377 -> 0.9367\n",
      "store r2 1378 -> 0.9197\n",
      "store r2 1379 -> 0.9374\n",
      "store r2 1380 -> 0.9168\n",
      "store r2 1381 -> 0.9703\n",
      "store r2 1382 -> 0.9324\n",
      "store r2 1383 -> 0.9558\n",
      "store r2 1384 -> 0.9412\n",
      "store r2 1385 -> 0.9113\n",
      "store r2 1386 -> 0.9736\n",
      "store r2 1387 -> 0.8461\n",
      "store r2 1388 -> 0.9355\n",
      "store r2 1389 -> 0.9475\n",
      "store r2 1390 -> 0.9448\n",
      "store r2 1391 -> 0.9479\n",
      "store r2 1392 -> 0.9289\n",
      "store r2 1393 -> 0.9488\n",
      "store r2 1394 -> 0.9235\n",
      "store r2 1395 -> 0.9334\n",
      "store r2 1396 -> 0.9327\n",
      "store r2 1397 -> 0.9614\n",
      "store r2 1398 -> 0.9736\n",
      "store r2 1399 -> 0.9034\n",
      "store r2 1400 -> 0.9515\n",
      "store r2 1401 -> 0.9100\n",
      "store r2 1402 -> 0.9598\n",
      "store r2 1403 -> 0.9277\n",
      "store r2 1404 -> 0.9496\n",
      "store r2 1405 -> 0.8976\n",
      "store r2 1406 -> 0.9416\n",
      "store r2 1407 -> 0.9608\n",
      "store r2 1408 -> 0.9513\n",
      "store r2 1409 -> 0.9044\n",
      "store r2 1410 -> 0.9199\n",
      "store r2 1411 -> 0.9611\n",
      "store r2 1412 -> 0.9701\n",
      "store r2 1413 -> 0.8658\n",
      "store r2 1414 -> 0.9573\n",
      "store r2 1415 -> 0.9262\n",
      "store r2 1416 -> 0.8884\n",
      "store r2 1417 -> 0.9230\n",
      "store r2 1418 -> 0.9207\n",
      "store r2 1419 -> 0.9442\n",
      "store r2 1420 -> 0.9671\n",
      "store r2 1421 -> 0.9020\n",
      "store r2 1422 -> 0.9304\n",
      "store r2 1423 -> 0.9508\n",
      "store r2 1424 -> 0.9689\n",
      "store r2 1425 -> 0.9401\n",
      "store r2 1426 -> 0.9319\n",
      "store r2 1427 -> 0.7369\n",
      "store r2 1428 -> 0.9662\n",
      "store r2 1429 -> 0.9532\n",
      "store r2 1430 -> 0.9612\n",
      "store r2 1431 -> 0.9475\n",
      "store r2 1432 -> 0.9040\n",
      "store r2 1433 -> 0.8785\n",
      "store r2 1434 -> 0.9522\n",
      "store r2 1435 -> 0.9302\n",
      "store r2 1436 -> 0.9289\n",
      "store r2 1437 -> 0.9419\n",
      "store r2 1438 -> 0.8473\n",
      "store r2 1439 -> 0.8819\n",
      "store r2 1440 -> 0.9686\n",
      "store r2 1441 -> 0.9160\n",
      "store r2 1442 -> 0.9438\n",
      "store r2 1443 -> 0.8063\n",
      "store r2 1444 -> 0.9323\n",
      "store r2 1445 -> 0.7886\n",
      "store r2 1446 -> 0.9280\n",
      "store r2 1447 -> 0.9600\n",
      "store r2 1448 -> 0.9282\n",
      "store r2 1449 -> 0.9401\n",
      "store r2 1450 -> 0.8811\n",
      "store r2 1451 -> 0.8566\n",
      "store r2 1452 -> 0.9714\n",
      "store r2 1453 -> 0.9311\n",
      "store r2 1454 -> 0.7783\n",
      "store r2 1455 -> 0.9546\n",
      "store r2 1456 -> 0.9276\n",
      "store r2 1457 -> 0.9046\n",
      "store r2 1458 -> 0.9527\n",
      "store r2 1459 -> 0.9418\n",
      "store r2 1460 -> 0.8896\n",
      "store r2 1461 -> 0.9530\n",
      "store r2 1462 -> 0.9505\n",
      "store r2 1463 -> 0.9545\n",
      "store r2 1464 -> 0.8573\n",
      "store r2 1465 -> 0.9417\n",
      "store r2 1466 -> 0.9632\n",
      "store r2 1467 -> 0.9555\n",
      "store r2 1468 -> 0.9529\n",
      "store r2 1469 -> 0.9596\n",
      "store r2 1470 -> 0.8631\n",
      "store r2 1471 -> 0.9414\n",
      "store r2 1472 -> 0.9628\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "scores = {}\n",
    "scores_mae= {}\n",
    "predictions = defaultdict(dict)\n",
    "store_pred = {}\n",
    "shopping_center_ids = [1129,1267,1280,1307,1330,1339,1357,1387,1676]\n",
    "region2_stores = all_train[all_train['Region_2'] ==1]['StoreID'].unique()\n",
    "ids = all_train.StoreID.unique()\n",
    "\n",
    "for storeid in ids:\n",
    "    \n",
    "    model1= Lasso(alpha=20)\n",
    "    model2 =XGBRegressor(n_estimators=100)\n",
    "    model3 = GradientBoostingRegressor(n_estimators=50, max_depth=5,learning_rate=0.07,\n",
    "                                      loss='huber',random_state =5)\n",
    "    \n",
    "    model4 = ExtraTreesRegressor(n_estimators=50)\n",
    "\n",
    "    \n",
    "    model = AveragingModels(models = (model1,model2,model3,model4)) \n",
    "\n",
    "    # split the dataset\n",
    "    train = all_train[all_train.StoreID == storeid]\n",
    "    \n",
    "    x_train, y_train, x_test, y_test =\\\n",
    "    split_dataset_bymonth(2017,[3,4], train)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # train the model with the training set\n",
    "    model.fit(x_train, y_train)\n",
    "              \n",
    "    # scoring\n",
    "    scores[storeid] = r2_score(y_test, model.predict(x_test))\n",
    "    scores_mae[storeid]= mean_absolute_error(y_test, model.predict(x_test))\n",
    "    \n",
    "    print('store r2 {} -> {:.4f}'.format(storeid, scores[storeid]))\n",
    "#     print('store mae {} -> {:.2f}'.format(storeid, scores_mae[storeid]))\n",
    "    \n",
    "    store_pred[storeid] = scores[storeid]\n",
    "    # predict the test set with the trained model\n",
    "    for month in x_test.month.unique():\n",
    "        # get daily predictions for each month in the test set\n",
    "        month_prediction =model.predict(x_test[x_test.month == month]).astype(\"int\")\n",
    "        month_actual = y_test.loc[x_test[x_test.month == month].index].values\n",
    "        \n",
    "#         if scores[storeid] <0.6 :\n",
    "#             ts_pred = pd.Series(month_prediction, index=x_test[x_test.month==month]['day_of_month']).\\\n",
    "#                 plot(figsize=(20,5), title='Region 2', marker='o')\n",
    "#             ts_act = pd.Series(month_actual, index=x_test[x_test.month==month]['day_of_month']).\\\n",
    "#                 plot(figsize=(20,5), title='Region 2', marker='x')\n",
    "#             plt.show()\n",
    "        \n",
    "        # store the monthly mean of the test set\n",
    "        predictions[storeid][month] = {\n",
    "            'predicted': np.sum(month_prediction),\n",
    "            'actual': np.sum(month_actual)        \n",
    "        }\n",
    "#     predictions[storeid]['r2']=scores[storeid]\n",
    "#     predictions[storeid]['mae']=scores_mae[storeid]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Lanzi error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of regions\n",
    "R = sorted(all_train_orig.Region.unique().astype(int))\n",
    "# set of predicted months\n",
    "months = [key for key, value in predictions[1000].items()]\n",
    "# set of stores by region\n",
    "dict_store_byRegion = all_train_orig[['Region', 'StoreID']].drop_duplicates()\\\n",
    ".set_index('StoreID').groupby('Region').groups\n",
    "\n",
    "def region_error(region, predictions):    \n",
    "    num = 0\n",
    "    den = 0\n",
    "    for store in dict_store_byRegion[str(region)]:\n",
    "        for month in months:\n",
    "            predicted = predictions[store][month]['predicted']\n",
    "            actual = predictions[store][month]['actual']\n",
    "            \n",
    "            num += abs(actual - predicted)\n",
    "            den += actual\n",
    "    \n",
    "    return num/den\n",
    "    \n",
    "# total_error input:\n",
    "#\n",
    "# region_errors = [0.3, 0.5, ... ]\n",
    "\n",
    "def total_error(region_errors):\n",
    "#     print(region_errors)\n",
    "    return sum(region_errors)/len(region_errors)\n",
    "\n",
    "def lanzi_error(predictions):\n",
    "    region_errors = []\n",
    "    for r in R:\n",
    "        region_errors.append(region_error(r, predictions))\n",
    "    \n",
    "    return total_error(region_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lanzi error: {}'.format(lanzi_error(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
