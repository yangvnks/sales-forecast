{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.linear_model import Lasso,Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None) # no truncate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment settings\n",
    "data_path_out = 'Data/output/'\n",
    "    \n",
    "# Deserialize previously saved data from \"data-visualization\"\n",
    "with open(data_path_out + 'train_pp.obj', 'rb') as file:\n",
    "    all_train = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_orig = all_train.copy()\n",
    "all_train = all_train.drop('Region',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop now useless variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = all_train.drop(labels = ['NumberOfCustomers'],axis=1)\n",
    "all_train = all_train.drop('Date',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "    \n",
    "# model = Lasso(alpha=50)\n",
    "# model2 = Ridge(alpha=1)\n",
    "# model3 =XGBRegressor(max_depth=4,\n",
    "#                             gamma=0.05, \n",
    "#                             learning_rate=0.05, \n",
    "#                                  n_estimators=500,\n",
    "#                                  subsample=0.3, silent=1,\n",
    "#                                  random_state =7, nthread = -1)\n",
    "\n",
    "# model4 = GradientBoostingRegressor(n_estimators=500, learning_rate=0.05,\n",
    "#                                        max_depth=2,loss='lad',random_state =5)\n",
    "\n",
    "\n",
    "# model = AveragingModels(models = (model1,model2,model3,model4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation store by store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {}\n",
    "# for storeid in all_train.StoreID.unique():\n",
    "#     train = all_train[all_train.StoreID == storeid]\n",
    "#     y_train = train.NumberOfSales\n",
    "#     x_train = train.drop('NumberOfSales',axis = 1)\n",
    "#     kfold = KFold(n_splits=10,shuffle = True, random_state=7)\n",
    "#     results[storeid] = cross_val_score(model, x_train, y_train, scoring='r2', cv=kfold)\n",
    "#     print('Cross-validation for {} -> score: {:.4f} with +/- {:.4f}'\\\n",
    "#           .format(storeid,results[storeid].mean(),results[storeid].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results = pd.DataFrame.from_dict(results).T\n",
    "# df_results_mean = df_results.mean(axis=1)\n",
    "# df_results_mean[df_results_mean < 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = all_train.drop(\"Differential\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lanzi Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train by month\n",
    "def split_dataset_bymonth(test_year, test_months, train_set):\n",
    "    test_mask = (train.year == test_year) & train.month.isin(test_months)\n",
    "    \n",
    "    # define the train set\n",
    "    train_dataset = train[~test_mask]\n",
    "    x_train = train_dataset.drop('NumberOfSales', axis=1)\n",
    "    y_train = train_dataset.NumberOfSales\n",
    "    \n",
    "    # define the test set\n",
    "    test_dataset = train[test_mask]\n",
    "    x_test = test_dataset.drop('NumberOfSales', axis=1)\n",
    "    y_test = test_dataset.NumberOfSales\n",
    "    \n",
    "    return (x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store 1000 -> 0.8062\n",
      "store 1001 -> 0.8053\n",
      "store 1002 -> 0.9569\n",
      "store 1003 -> 0.9369\n",
      "store 1004 -> 0.9492\n",
      "store 1005 -> 0.9115\n",
      "store 1006 -> 0.9159\n",
      "store 1007 -> 0.8923\n",
      "store 1008 -> 0.8381\n",
      "store 1009 -> 0.9293\n",
      "store 1010 -> 0.9010\n",
      "store 1011 -> 0.9132\n",
      "store 1012 -> 0.9630\n",
      "store 1013 -> 0.9619\n",
      "store 1014 -> 0.9215\n",
      "store 1015 -> 0.9395\n",
      "store 1016 -> 0.8904\n",
      "store 1017 -> 0.9468\n",
      "store 1018 -> 0.9245\n",
      "store 1019 -> 0.9567\n",
      "store 1020 -> 0.9069\n",
      "store 1021 -> 0.9547\n",
      "store 1022 -> 0.9243\n",
      "store 1023 -> 0.9508\n",
      "store 1024 -> 0.9405\n",
      "store 1025 -> 0.8528\n",
      "store 1026 -> 0.9473\n",
      "store 1027 -> 0.9299\n",
      "store 1028 -> 0.8854\n",
      "store 1029 -> 0.9551\n",
      "store 1030 -> 0.9162\n",
      "store 1031 -> 0.8641\n",
      "store 1032 -> 0.9510\n",
      "store 1033 -> 0.9754\n",
      "store 1034 -> 0.8985\n",
      "store 1035 -> 0.9604\n",
      "store 1036 -> 0.9225\n",
      "store 1037 -> 0.8780\n",
      "store 1038 -> 0.9069\n",
      "store 1039 -> 0.9475\n",
      "store 1040 -> 0.9529\n",
      "store 1041 -> 0.9312\n",
      "store 1042 -> 0.9321\n",
      "store 1043 -> 0.8470\n",
      "store 1044 -> 0.9552\n",
      "store 1045 -> 0.9386\n",
      "store 1046 -> 0.9165\n",
      "store 1047 -> 0.8503\n",
      "store 1048 -> 0.9119\n",
      "store 1049 -> 0.7814\n",
      "store 1050 -> 0.9596\n",
      "store 1051 -> 0.9131\n",
      "store 1052 -> 0.9344\n",
      "store 1053 -> 0.9200\n",
      "store 1054 -> 0.8141\n",
      "store 1055 -> 0.9256\n",
      "store 1056 -> 0.9201\n",
      "store 1057 -> 0.9362\n",
      "store 1058 -> 0.8805\n",
      "store 1059 -> 0.9656\n",
      "store 1060 -> 0.9586\n",
      "store 1061 -> 0.9597\n",
      "store 1062 -> 0.9585\n",
      "store 1063 -> 0.9623\n",
      "store 1064 -> 0.9549\n",
      "store 1065 -> 0.9133\n",
      "store 1066 -> 0.9345\n",
      "store 1067 -> 0.9153\n",
      "store 1068 -> 0.7597\n",
      "store 1069 -> 0.9122\n",
      "store 1070 -> 0.9227\n",
      "store 1071 -> 0.9384\n",
      "store 1072 -> 0.9309\n",
      "store 1073 -> 0.9423\n",
      "store 1074 -> 0.9184\n",
      "store 1075 -> 0.9018\n",
      "store 1076 -> 0.9349\n",
      "store 1077 -> 0.8465\n",
      "store 1078 -> 0.9494\n",
      "store 1079 -> 0.9210\n",
      "store 1080 -> 0.8453\n",
      "store 1081 -> 0.9414\n",
      "store 1082 -> 0.8958\n",
      "store 1083 -> 0.8942\n",
      "store 1084 -> 0.9600\n",
      "store 1085 -> 0.9503\n",
      "store 1086 -> 0.9184\n",
      "store 1087 -> 0.8458\n",
      "store 1088 -> 0.9683\n",
      "store 1089 -> 0.9325\n",
      "store 1090 -> 0.7078\n",
      "store 1091 -> 0.9609\n",
      "store 1092 -> 0.9310\n",
      "store 1093 -> 0.8806\n",
      "store 1094 -> 0.9100\n",
      "store 1095 -> 0.9342\n",
      "store 1096 -> 0.9202\n",
      "store 1097 -> 0.9299\n",
      "store 1098 -> 0.8736\n",
      "store 1099 -> 0.8734\n",
      "store 1100 -> 0.8822\n",
      "store 1101 -> 0.8988\n",
      "store 1102 -> 0.9308\n",
      "store 1103 -> 0.9380\n",
      "store 1104 -> 0.8976\n",
      "store 1105 -> 0.9256\n",
      "store 1106 -> 0.8976\n",
      "store 1107 -> 0.9256\n",
      "store 1108 -> 0.7186\n",
      "store 1109 -> 0.9221\n",
      "store 1110 -> 0.9490\n",
      "store 1111 -> 0.8728\n",
      "store 1112 -> 0.9531\n",
      "store 1113 -> 0.8916\n",
      "store 1114 -> 0.6959\n",
      "store 1115 -> 0.9584\n",
      "store 1116 -> 0.9135\n",
      "store 1117 -> 0.8496\n",
      "store 1118 -> 0.9403\n",
      "store 1119 -> 0.8988\n",
      "store 1120 -> 0.9508\n",
      "store 1121 -> 0.9123\n",
      "store 1122 -> 0.9234\n",
      "store 1123 -> 0.9019\n",
      "store 1124 -> 0.9278\n",
      "store 1125 -> 0.8723\n",
      "store 1126 -> 0.9472\n",
      "store 1127 -> 0.9351\n",
      "store 1128 -> 0.9311\n",
      "store 1129 -> 0.7886\n",
      "store 1130 -> 0.8934\n",
      "store 1131 -> 0.9145\n",
      "store 1132 -> 0.9328\n",
      "store 1133 -> 0.9405\n",
      "store 1134 -> 0.8985\n",
      "store 1135 -> 0.9116\n",
      "store 1136 -> 0.9080\n",
      "store 1137 -> 0.8649\n",
      "store 1138 -> 0.8395\n",
      "store 1139 -> 0.9173\n",
      "store 1140 -> 0.9539\n",
      "store 1141 -> 0.9412\n",
      "store 1142 -> 0.9322\n",
      "store 1143 -> 0.9137\n",
      "store 1144 -> 0.9370\n",
      "store 1145 -> 0.9231\n",
      "store 1146 -> 0.9310\n",
      "store 1147 -> 0.9255\n",
      "store 1148 -> 0.9273\n",
      "store 1149 -> 0.9391\n",
      "store 1150 -> 0.9173\n",
      "store 1151 -> 0.9199\n",
      "store 1152 -> 0.9405\n",
      "store 1153 -> 0.9307\n",
      "store 1154 -> 0.9116\n",
      "store 1155 -> 0.9696\n",
      "store 1156 -> 0.9618\n",
      "store 1157 -> 0.9342\n",
      "store 1158 -> 0.9422\n",
      "store 1159 -> 0.9272\n",
      "store 1160 -> 0.9470\n",
      "store 1161 -> 0.8717\n",
      "store 1162 -> 0.8958\n",
      "store 1163 -> 0.9495\n",
      "store 1164 -> 0.9267\n",
      "store 1165 -> 0.7960\n",
      "store 1166 -> 0.8928\n",
      "store 1167 -> 0.8655\n",
      "store 1168 -> 0.9275\n",
      "store 1169 -> 0.9130\n",
      "store 1170 -> 0.9603\n",
      "store 1171 -> 0.8981\n",
      "store 1172 -> 0.9154\n",
      "store 1173 -> 0.9419\n",
      "store 1174 -> 0.9265\n",
      "store 1175 -> 0.8880\n",
      "store 1176 -> 0.9520\n",
      "store 1177 -> 0.9390\n",
      "store 1178 -> 0.9213\n",
      "store 1179 -> 0.9367\n",
      "store 1180 -> 0.9568\n",
      "store 1181 -> 0.9638\n",
      "store 1182 -> 0.9177\n",
      "store 1183 -> 0.8904\n",
      "store 1184 -> 0.9195\n",
      "store 1185 -> 0.9397\n",
      "store 1186 -> 0.9392\n",
      "store 1187 -> 0.8819\n",
      "store 1188 -> 0.9355\n",
      "store 1189 -> 0.8913\n",
      "store 1190 -> 0.9041\n",
      "store 1191 -> 0.9546\n",
      "store 1192 -> 0.8573\n",
      "store 1193 -> 0.9109\n",
      "store 1194 -> 0.8994\n",
      "store 1195 -> 0.9363\n",
      "store 1196 -> 0.9010\n",
      "store 1197 -> 0.9717\n",
      "store 1198 -> 0.9554\n",
      "store 1199 -> 0.9390\n",
      "store 1200 -> 0.8988\n",
      "store 1201 -> 0.9449\n",
      "store 1202 -> 0.9198\n",
      "store 1203 -> 0.8421\n",
      "store 1204 -> 0.9065\n",
      "store 1205 -> 0.9029\n",
      "store 1206 -> 0.8371\n",
      "store 1207 -> 0.9554\n",
      "store 1208 -> 0.8583\n",
      "store 1209 -> 0.9213\n",
      "store 1210 -> 0.9485\n",
      "store 1211 -> 0.8823\n",
      "store 1212 -> 0.9550\n",
      "store 1213 -> 0.9488\n",
      "store 1214 -> 0.7865\n",
      "store 1215 -> 0.9495\n",
      "store 1216 -> 0.9084\n",
      "store 1217 -> 0.9078\n",
      "store 1218 -> 0.9260\n",
      "store 1219 -> 0.9151\n",
      "store 1220 -> 0.9417\n",
      "store 1221 -> 0.9395\n",
      "store 1222 -> 0.9369\n",
      "store 1223 -> 0.9243\n",
      "store 1224 -> 0.9356\n",
      "store 1225 -> 0.9451\n",
      "store 1226 -> 0.9094\n",
      "store 1227 -> 0.9217\n",
      "store 1228 -> 0.9461\n",
      "store 1229 -> 0.9393\n",
      "store 1230 -> 0.8942\n",
      "store 1231 -> 0.9291\n",
      "store 1232 -> 0.9040\n",
      "store 1233 -> 0.9075\n",
      "store 1234 -> 0.9513\n",
      "store 1235 -> 0.9756\n",
      "store 1236 -> 0.9139\n",
      "store 1237 -> 0.9133\n",
      "store 1238 -> 0.9594\n",
      "store 1239 -> 0.8760\n",
      "store 1240 -> 0.9520\n",
      "store 1241 -> 0.9608\n",
      "store 1242 -> 0.8978\n",
      "store 1243 -> 0.9492\n",
      "store 1244 -> 0.9468\n",
      "store 1245 -> 0.9491\n",
      "store 1246 -> 0.8362\n",
      "store 1247 -> 0.9224\n",
      "store 1248 -> 0.9072\n",
      "store 1249 -> 0.9439\n",
      "store 1250 -> 0.9525\n",
      "store 1251 -> 0.9438\n",
      "store 1252 -> 0.9364\n",
      "store 1253 -> 0.9627\n",
      "store 1254 -> 0.9377\n",
      "store 1255 -> 0.9540\n",
      "store 1256 -> 0.9496\n",
      "store 1257 -> 0.9125\n",
      "store 1258 -> 0.9492\n",
      "store 1259 -> 0.8780\n",
      "store 1260 -> 0.9244\n",
      "store 1261 -> 0.8922\n",
      "store 1262 -> 0.8919\n",
      "store 1263 -> 0.9603\n",
      "store 1264 -> 0.8945\n",
      "store 1265 -> 0.9273\n",
      "store 1266 -> 0.9187\n",
      "store 1267 -> 0.7702\n",
      "store 1268 -> 0.9278\n",
      "store 1269 -> 0.8992\n",
      "store 1270 -> 0.9065\n",
      "store 1271 -> 0.8315\n",
      "store 1272 -> 0.9719\n",
      "store 1273 -> 0.9298\n",
      "store 1274 -> 0.9359\n",
      "store 1275 -> 0.9440\n",
      "store 1276 -> 0.9458\n",
      "store 1277 -> 0.8936\n",
      "store 1278 -> 0.9466\n",
      "store 1279 -> 0.8623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yannickgiovanakis/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store 1280 -> 0.8175\n",
      "store 1281 -> 0.8983\n",
      "store 1282 -> 0.9156\n",
      "store 1283 -> 0.9238\n",
      "store 1284 -> 0.9118\n",
      "store 1285 -> 0.8481\n",
      "store 1286 -> 0.9652\n",
      "store 1287 -> 0.9432\n",
      "store 1288 -> 0.9273\n",
      "store 1289 -> 0.9094\n",
      "store 1290 -> 0.8500\n",
      "store 1291 -> 0.8695\n",
      "store 1292 -> 0.9223\n",
      "store 1293 -> 0.9176\n",
      "store 1294 -> 0.8510\n",
      "store 1295 -> 0.9062\n",
      "store 1296 -> 0.8827\n",
      "store 1297 -> 0.9578\n",
      "store 1298 -> 0.9401\n",
      "store 1299 -> 0.8979\n",
      "store 1300 -> 0.9570\n",
      "store 1301 -> 0.9109\n",
      "store 1302 -> 0.9542\n",
      "store 1303 -> 0.7846\n",
      "store 1304 -> 0.9558\n",
      "store 1305 -> 0.8739\n",
      "store 1306 -> 0.8810\n",
      "store 1307 -> 0.5976\n",
      "store 1308 -> 0.9665\n",
      "store 1309 -> 0.9242\n",
      "store 1310 -> 0.8517\n",
      "store 1311 -> 0.9079\n",
      "store 1312 -> 0.8652\n",
      "store 1313 -> 0.9423\n",
      "store 1314 -> 0.9156\n",
      "store 1315 -> 0.8732\n",
      "store 1316 -> 0.9328\n",
      "store 1317 -> 0.9111\n",
      "store 1318 -> 0.9156\n",
      "store 1319 -> 0.9199\n",
      "store 1320 -> 0.9653\n",
      "store 1321 -> 0.9392\n",
      "store 1322 -> 0.9261\n",
      "store 1323 -> 0.9239\n",
      "store 1324 -> 0.8949\n",
      "store 1325 -> 0.9547\n",
      "store 1326 -> 0.8847\n",
      "store 1327 -> 0.9487\n",
      "store 1328 -> 0.9305\n",
      "store 1329 -> 0.9224\n",
      "store 1330 -> 0.3437\n",
      "store 1331 -> 0.9503\n",
      "store 1332 -> 0.8131\n",
      "store 1333 -> 0.9476\n",
      "store 1334 -> 0.8881\n",
      "store 1335 -> 0.9164\n",
      "store 1336 -> 0.5810\n",
      "store 1337 -> 0.9079\n",
      "store 1338 -> 0.9161\n",
      "store 1339 -> 0.6277\n",
      "store 1340 -> 0.9474\n",
      "store 1341 -> 0.9197\n",
      "store 1342 -> 0.9512\n",
      "store 1343 -> 0.9487\n",
      "store 1344 -> 0.8909\n",
      "store 1345 -> 0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yannickgiovanakis/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store 1346 -> 0.8427\n",
      "store 1347 -> 0.9427\n",
      "store 1348 -> 0.9025\n",
      "store 1349 -> 0.8273\n",
      "store 1350 -> 0.9436\n",
      "store 1351 -> 0.8538\n",
      "store 1352 -> 0.7958\n",
      "store 1353 -> 0.9410\n",
      "store 1354 -> 0.9264\n",
      "store 1355 -> 0.9694\n",
      "store 1356 -> 0.9321\n",
      "store 1357 -> 0.8060\n",
      "store 1358 -> 0.9591\n",
      "store 1359 -> 0.8862\n",
      "store 1360 -> 0.9138\n",
      "store 1361 -> 0.9710\n",
      "store 1362 -> 0.9202\n",
      "store 1363 -> 0.9506\n",
      "store 1364 -> 0.8525\n",
      "store 1365 -> 0.9564\n",
      "store 1366 -> 0.9510\n",
      "store 1367 -> 0.8273\n",
      "store 1368 -> 0.9107\n",
      "store 1369 -> 0.9270\n",
      "store 1370 -> 0.8165\n",
      "store 1371 -> 0.9531\n",
      "store 1372 -> 0.9404\n",
      "store 1373 -> 0.9114\n",
      "store 1374 -> 0.9004\n",
      "store 1375 -> 0.9368\n",
      "store 1376 -> 0.9571\n",
      "store 1377 -> 0.9302\n",
      "store 1378 -> 0.9017\n",
      "store 1379 -> 0.9201\n",
      "store 1380 -> 0.9089\n",
      "store 1381 -> 0.9635\n",
      "store 1382 -> 0.9256\n",
      "store 1383 -> 0.9478\n",
      "store 1384 -> 0.9218\n",
      "store 1385 -> 0.9112\n",
      "store 1386 -> 0.9706\n",
      "store 1387 -> 0.7782\n",
      "store 1388 -> 0.9305\n",
      "store 1389 -> 0.9397\n",
      "store 1390 -> 0.9312\n",
      "store 1391 -> 0.9342\n",
      "store 1392 -> 0.9132\n",
      "store 1393 -> 0.9365\n",
      "store 1394 -> 0.9173\n",
      "store 1395 -> 0.9293\n",
      "store 1396 -> 0.9204\n",
      "store 1397 -> 0.9463\n",
      "store 1398 -> 0.9599\n",
      "store 1399 -> 0.8984\n",
      "store 1400 -> 0.9451\n",
      "store 1401 -> 0.8912\n",
      "store 1402 -> 0.9516\n",
      "store 1403 -> 0.9211\n",
      "store 1404 -> 0.9380\n",
      "store 1405 -> 0.8843\n",
      "store 1406 -> 0.9274\n",
      "store 1407 -> 0.9551\n",
      "store 1408 -> 0.9476\n",
      "store 1409 -> 0.9053\n",
      "store 1410 -> 0.9075\n",
      "store 1411 -> 0.9555\n",
      "store 1412 -> 0.9669\n",
      "store 1413 -> 0.8599\n",
      "store 1414 -> 0.9382\n",
      "store 1415 -> 0.9191\n",
      "store 1416 -> 0.8780\n",
      "store 1417 -> 0.9202\n",
      "store 1418 -> 0.8907\n",
      "store 1419 -> 0.9374\n",
      "store 1420 -> 0.9577\n",
      "store 1421 -> 0.8862\n",
      "store 1422 -> 0.9143\n",
      "store 1423 -> 0.9424\n",
      "store 1424 -> 0.9583\n",
      "store 1425 -> 0.9354\n",
      "store 1426 -> 0.9104\n",
      "store 1427 -> 0.7287\n",
      "store 1428 -> 0.9579\n",
      "store 1429 -> 0.9295\n",
      "store 1430 -> 0.9551\n",
      "store 1431 -> 0.9329\n",
      "store 1432 -> 0.8856\n",
      "store 1433 -> 0.8805\n",
      "store 1434 -> 0.9382\n",
      "store 1435 -> 0.9196\n",
      "store 1436 -> 0.9218\n",
      "store 1437 -> 0.9372\n",
      "store 1438 -> 0.8538\n",
      "store 1439 -> 0.8471\n",
      "store 1440 -> 0.9632\n",
      "store 1441 -> 0.9092\n",
      "store 1442 -> 0.9457\n",
      "store 1443 -> 0.7490\n",
      "store 1444 -> 0.9164\n",
      "store 1445 -> 0.7462\n",
      "store 1446 -> 0.9121\n",
      "store 1447 -> 0.9507\n",
      "store 1448 -> 0.9037\n",
      "store 1449 -> 0.9302\n",
      "store 1450 -> 0.8670\n",
      "store 1451 -> 0.8621\n",
      "store 1452 -> 0.9624\n",
      "store 1453 -> 0.9287\n",
      "store 1454 -> 0.7635\n",
      "store 1455 -> 0.9437\n",
      "store 1456 -> 0.9315\n",
      "store 1457 -> 0.8895\n",
      "store 1458 -> 0.9450\n",
      "store 1459 -> 0.9344\n",
      "store 1460 -> 0.8865\n",
      "store 1461 -> 0.9475\n",
      "store 1462 -> 0.9399\n",
      "store 1463 -> 0.9403\n",
      "store 1464 -> 0.8663\n",
      "store 1465 -> 0.9353\n",
      "store 1466 -> 0.9548\n",
      "store 1467 -> 0.9404\n",
      "store 1468 -> 0.9492\n",
      "store 1469 -> 0.9399\n",
      "store 1470 -> 0.8555\n",
      "store 1471 -> 0.9332\n",
      "store 1472 -> 0.9568\n",
      "store 1473 -> 0.9198\n",
      "store 1474 -> 0.9475\n",
      "store 1475 -> 0.9278\n",
      "store 1476 -> 0.9386\n",
      "store 1477 -> 0.9584\n",
      "store 1478 -> 0.9116\n",
      "store 1479 -> 0.9348\n",
      "store 1480 -> 0.9544\n",
      "store 1481 -> 0.9493\n",
      "store 1482 -> 0.9538\n",
      "store 1483 -> 0.9292\n",
      "store 1484 -> 0.9144\n",
      "store 1485 -> 0.8957\n",
      "store 1486 -> 0.9378\n",
      "store 1487 -> 0.9371\n",
      "store 1488 -> 0.9139\n",
      "store 1489 -> 0.9116\n",
      "store 1490 -> 0.9432\n",
      "store 1491 -> 0.9723\n",
      "store 1492 -> 0.9018\n",
      "store 1493 -> 0.9119\n",
      "store 1494 -> 0.9247\n",
      "store 1495 -> 0.9170\n",
      "store 1496 -> 0.8944\n",
      "store 1497 -> 0.8990\n",
      "store 1498 -> 0.9534\n",
      "store 1499 -> 0.8965\n",
      "store 1500 -> 0.8814\n",
      "store 1501 -> 0.9598\n",
      "store 1502 -> 0.8758\n",
      "store 1503 -> 0.9306\n",
      "store 1504 -> 0.9344\n",
      "store 1505 -> 0.9244\n",
      "store 1506 -> 0.8813\n",
      "store 1507 -> 0.9212\n",
      "store 1508 -> 0.9138\n",
      "store 1509 -> 0.9061\n",
      "store 1510 -> 0.8219\n",
      "store 1511 -> 0.9470\n",
      "store 1512 -> 0.8542\n",
      "store 1513 -> 0.8694\n",
      "store 1514 -> 0.9294\n",
      "store 1515 -> 0.8895\n",
      "store 1516 -> 0.9241\n",
      "store 1517 -> 0.7403\n",
      "store 1518 -> 0.9335\n",
      "store 1519 -> 0.9034\n",
      "store 1520 -> 0.8377\n",
      "store 1521 -> 0.9488\n",
      "store 1522 -> 0.9228\n",
      "store 1523 -> 0.8940\n",
      "store 1524 -> 0.9106\n",
      "store 1525 -> 0.9130\n",
      "store 1526 -> 0.9465\n",
      "store 1527 -> 0.8614\n",
      "store 1528 -> 0.9427\n",
      "store 1529 -> 0.8589\n",
      "store 1530 -> 0.8699\n",
      "store 1531 -> 0.9100\n",
      "store 1532 -> 0.9386\n",
      "store 1533 -> 0.8497\n",
      "store 1534 -> 0.9106\n",
      "store 1535 -> 0.9188\n",
      "store 1536 -> 0.9043\n",
      "store 1537 -> 0.9188\n",
      "store 1538 -> 0.9696\n",
      "store 1539 -> 0.8979\n",
      "store 1540 -> 0.8626\n",
      "store 1541 -> 0.9119\n",
      "store 1542 -> 0.8848\n",
      "store 1543 -> 0.9655\n",
      "store 1544 -> 0.8945\n",
      "store 1545 -> 0.8844\n",
      "store 1546 -> 0.7563\n",
      "store 1547 -> 0.9442\n",
      "store 1548 -> 0.9529\n",
      "store 1549 -> 0.9246\n",
      "store 1550 -> 0.9553\n",
      "store 1551 -> 0.8989\n",
      "store 1552 -> 0.9545\n",
      "store 1553 -> 0.9556\n",
      "store 1554 -> 0.9616\n",
      "store 1555 -> 0.9474\n",
      "store 1556 -> 0.9083\n",
      "store 1557 -> 0.9143\n",
      "store 1558 -> 0.8503\n",
      "store 1559 -> 0.8253\n",
      "store 1560 -> 0.9311\n",
      "store 1561 -> 0.9449\n",
      "store 1562 -> 0.9421\n",
      "store 1563 -> 0.9725\n",
      "store 1564 -> 0.9501\n",
      "store 1565 -> 0.9397\n",
      "store 1566 -> 0.9487\n",
      "store 1567 -> 0.9423\n",
      "store 1568 -> 0.8522\n",
      "store 1569 -> 0.9395\n",
      "store 1570 -> 0.9598\n",
      "store 1571 -> 0.8981\n",
      "store 1572 -> 0.9264\n",
      "store 1573 -> 0.9412\n",
      "store 1574 -> 0.9398\n",
      "store 1575 -> 0.9177\n",
      "store 1576 -> 0.9448\n",
      "store 1577 -> 0.9210\n",
      "store 1578 -> 0.9199\n",
      "store 1579 -> 0.8795\n",
      "store 1580 -> 0.9270\n",
      "store 1581 -> 0.8881\n",
      "store 1582 -> 0.9414\n",
      "store 1583 -> 0.8258\n",
      "store 1584 -> 0.9061\n",
      "store 1585 -> 0.9159\n",
      "store 1586 -> 0.8917\n",
      "store 1587 -> 0.8877\n",
      "store 1588 -> 0.9370\n",
      "store 1589 -> 0.9458\n",
      "store 1590 -> 0.9461\n",
      "store 1591 -> 0.9331\n",
      "store 1592 -> 0.9281\n",
      "store 1593 -> 0.8246\n",
      "store 1594 -> 0.8400\n",
      "store 1595 -> 0.8482\n",
      "store 1596 -> 0.9470\n",
      "store 1597 -> 0.9672\n",
      "store 1598 -> 0.8947\n",
      "store 1599 -> 0.7961\n",
      "store 1600 -> 0.9116\n",
      "store 1601 -> 0.9038\n",
      "store 1602 -> 0.9381\n",
      "store 1603 -> 0.9572\n",
      "store 1604 -> 0.9221\n",
      "store 1605 -> 0.8898\n",
      "store 1606 -> 0.9249\n",
      "store 1607 -> 0.9277\n",
      "store 1608 -> 0.8364\n",
      "store 1609 -> 0.9340\n",
      "store 1610 -> 0.8903\n",
      "store 1611 -> 0.9217\n",
      "store 1612 -> 0.9535\n",
      "store 1613 -> 0.9037\n",
      "store 1614 -> 0.9312\n",
      "store 1615 -> 0.5977\n",
      "store 1616 -> 0.8381\n",
      "store 1617 -> 0.9052\n",
      "store 1618 -> 0.9437\n",
      "store 1619 -> 0.8902\n",
      "store 1620 -> 0.9420\n",
      "store 1621 -> 0.9617\n",
      "store 1622 -> 0.9121\n",
      "store 1623 -> 0.8629\n",
      "store 1624 -> 0.9499\n",
      "store 1625 -> 0.9396\n",
      "store 1626 -> 0.9627\n",
      "store 1627 -> 0.9500\n",
      "store 1628 -> 0.9445\n",
      "store 1629 -> 0.9217\n",
      "store 1630 -> 0.8120\n",
      "store 1631 -> 0.9099\n",
      "store 1632 -> 0.9505\n",
      "store 1633 -> 0.9314\n",
      "store 1634 -> 0.8951\n",
      "store 1635 -> 0.9013\n",
      "store 1636 -> 0.9321\n",
      "store 1637 -> 0.9506\n",
      "store 1638 -> 0.9131\n",
      "store 1639 -> 0.9566\n",
      "store 1640 -> 0.8893\n",
      "store 1641 -> 0.9634\n",
      "store 1642 -> 0.8924\n",
      "store 1643 -> 0.8845\n",
      "store 1644 -> 0.9468\n",
      "store 1645 -> 0.9049\n",
      "store 1646 -> 0.9234\n",
      "store 1647 -> 0.9310\n",
      "store 1648 -> 0.8223\n",
      "store 1649 -> 0.9235\n",
      "store 1650 -> 0.9408\n",
      "store 1651 -> 0.9220\n",
      "store 1652 -> 0.8375\n",
      "store 1653 -> 0.8902\n",
      "store 1654 -> 0.9164\n",
      "store 1655 -> 0.8640\n",
      "store 1656 -> 0.9515\n",
      "store 1657 -> 0.9605\n",
      "store 1658 -> 0.8846\n",
      "store 1659 -> 0.9318\n",
      "store 1660 -> 0.9304\n",
      "store 1661 -> 0.9713\n",
      "store 1662 -> 0.9467\n",
      "store 1663 -> 0.9396\n",
      "store 1664 -> 0.9278\n",
      "store 1665 -> 0.8444\n",
      "store 1666 -> 0.9242\n",
      "store 1667 -> 0.9052\n",
      "store 1668 -> 0.8766\n",
      "store 1669 -> 0.9159\n",
      "store 1670 -> 0.9310\n",
      "store 1671 -> 0.8802\n",
      "store 1672 -> 0.9363\n",
      "store 1673 -> 0.9503\n",
      "store 1674 -> 0.9738\n",
      "store 1675 -> 0.9097\n",
      "store 1676 -> 0.9213\n",
      "store 1677 -> 0.9439\n",
      "store 1678 -> 0.9615\n",
      "store 1679 -> 0.9277\n",
      "store 1680 -> 0.9040\n",
      "store 1681 -> 0.9153\n",
      "store 1682 -> 0.9650\n",
      "store 1683 -> 0.9606\n",
      "store 1684 -> 0.9273\n",
      "store 1685 -> 0.9260\n",
      "store 1686 -> 0.9404\n",
      "store 1687 -> 0.9266\n",
      "store 1688 -> 0.8814\n",
      "store 1689 -> 0.9347\n",
      "store 1690 -> 0.9067\n",
      "store 1691 -> 0.9322\n",
      "store 1692 -> 0.9429\n",
      "store 1693 -> 0.9398\n",
      "store 1694 -> 0.9108\n",
      "store 1695 -> 0.9505\n",
      "store 1696 -> 0.9569\n",
      "store 1697 -> 0.9332\n",
      "store 1698 -> 0.9680\n",
      "store 1699 -> 0.9656\n",
      "store 1700 -> 0.9448\n",
      "store 1701 -> 0.9314\n",
      "store 1702 -> 0.9311\n",
      "store 1703 -> 0.9247\n",
      "store 1704 -> 0.9213\n",
      "store 1705 -> 0.9495\n",
      "store 1706 -> 0.9663\n",
      "store 1707 -> 0.9463\n",
      "store 1708 -> 0.9441\n",
      "store 1709 -> 0.9104\n",
      "store 1710 -> 0.9095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yannickgiovanakis/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store 1711 -> 0.9042\n",
      "store 1712 -> 0.9165\n",
      "store 1713 -> 0.9054\n",
      "store 1714 -> 0.8887\n",
      "store 1715 -> 0.9393\n",
      "store 1716 -> 0.9016\n",
      "store 1717 -> 0.9182\n",
      "store 1718 -> 0.8803\n",
      "store 1719 -> 0.8940\n",
      "store 1720 -> 0.7151\n",
      "store 1721 -> 0.9488\n",
      "store 1722 -> 0.8648\n",
      "store 1723 -> 0.9069\n",
      "store 1724 -> 0.9321\n",
      "store 1725 -> 0.9523\n",
      "store 1726 -> 0.9398\n",
      "store 1727 -> 0.9274\n",
      "store 1728 -> 0.8587\n",
      "store 1729 -> 0.8106\n",
      "store 1730 -> 0.9351\n",
      "store 1731 -> 0.9466\n",
      "store 1732 -> 0.9208\n",
      "store 1733 -> 0.8595\n",
      "store 1734 -> 0.9072\n",
      "store 1735 -> 0.9261\n",
      "store 1736 -> 0.9388\n",
      "store 1737 -> 0.9057\n",
      "store 1738 -> 0.9482\n",
      "store 1739 -> 0.6765\n",
      "store 1740 -> 0.9242\n",
      "store 1741 -> 0.9304\n",
      "store 1742 -> 0.9394\n",
      "store 1743 -> 0.9222\n",
      "store 1744 -> 0.9322\n",
      "store 1745 -> 0.9523\n",
      "store 1746 -> 0.8906\n",
      "store 1747 -> 0.9411\n",
      "store 1748 -> 0.9232\n"
     ]
    }
   ],
   "source": [
    "# from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scores = {}\n",
    "predictions = defaultdict(dict)\n",
    "store_pred = {}\n",
    "shopping_center_ids = [1129,1267,1280,1307,1330,1339,1357,1387,1676]\n",
    "ids = all_train.StoreID.unique()\n",
    "for storeid in ids:\n",
    "    \n",
    "    model1 = Lasso(alpha=20)\n",
    "    model2 = Ridge(alpha=7)\n",
    "    model3 =XGBRegressor()\n",
    "\n",
    "    model4 = GradientBoostingRegressor(n_estimators=500, learning_rate=0.05,\n",
    "                                       max_depth=2,loss='lad',random_state =5)\n",
    "\n",
    "\n",
    "    model5 = ExtraTreesRegressor()\n",
    "    \n",
    "    model = AveragingModels(models = (model1,model2,model3,model4,model5)) \n",
    "    \n",
    "    # split the dataset\n",
    "    train = all_train[all_train.StoreID == storeid]\n",
    "        \n",
    "    x_train, y_train, x_test, y_test =\\\n",
    "    split_dataset_bymonth(2017, [3,4], train)\n",
    "    \n",
    "    # train the model with the training set\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # scoring\n",
    "    scores[storeid] = r2_score(y_test, model.predict(x_test))\n",
    "    print('store {} -> {:.4f}'.format(storeid, scores[storeid]))\n",
    "    store_pred[storeid] = scores[storeid]\n",
    "    # predict the test set with the trained model\n",
    "    for month in x_test.month.unique():\n",
    "        # get daily predictions for each month in the test set\n",
    "        month_prediction1 =model.predict(x_test[x_test.month == month])\n",
    "        month_actual = y_test.loc[x_test[x_test.month == month].index].values\n",
    "        \n",
    "        # store the monthly mean of the test set\n",
    "        predictions[storeid][month] = {\n",
    "            'predicted': np.sum(month_prediction),\n",
    "            'actual': np.sum(month_actual)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Lanzi error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of regions\n",
    "R = sorted(all_train_orig.Region.unique().astype(int))\n",
    "# set of predicted months\n",
    "months = [key for key, value in predictions[1000].items()]\n",
    "# set of stores by region\n",
    "dict_store_byRegion = all_train_orig[['Region', 'StoreID']].drop_duplicates()\\\n",
    ".set_index('StoreID').groupby('Region').groups\n",
    "\n",
    "\n",
    "def region_error(region, predictions):    \n",
    "    num = 0\n",
    "    den = 0\n",
    "    for store in dict_store_byRegion[str(region)]:\n",
    "        for month in months:\n",
    "            predicted = predictions[store][month]['predicted']\n",
    "            actual = predictions[store][month]['actual']\n",
    "            \n",
    "            num += abs(actual - predicted)\n",
    "            den += actual\n",
    "    \n",
    "    return num/den\n",
    "    \n",
    "# total_error input:\n",
    "#\n",
    "# region_errors = [0.3, 0.5, ... ]\n",
    "\n",
    "def total_error(region_errors):\n",
    "#     print(region_errors)\n",
    "    return sum(region_errors)/len(region_errors)\n",
    "\n",
    "def lanzi_error(predictions):\n",
    "    region_errors = []\n",
    "    for r in R:\n",
    "        region_errors.append(region_error(r, predictions))\n",
    "    \n",
    "    return total_error(region_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lanzi error: 0.26228652696055943\n"
     ]
    }
   ],
   "source": [
    "print('Lanzi error: {}'.format(lanzi_error(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
